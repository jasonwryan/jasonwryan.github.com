<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[jasonwryan.com]]></title>
  <link href="http://jasonwryan.github.com/atom.xml" rel="self"/>
  <link href="http://jasonwryan.github.com/"/>
  <updated>2014-01-20T12:56:27+13:00</updated>
  <id>http://jasonwryan.github.com/</id>
  <author>
    <name><![CDATA[Jason Ryan]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Scripting with udev]]></title>
    <link href="http://jasonwryan.github.com/blog/2014/01/20/udev/"/>
    <updated>2014-01-20T10:02:00+13:00</updated>
    <id>http://jasonwryan.github.com/blog/2014/01/20/udev</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/usb.jpg" title="Creative Commons image" >
One of the most satisfying aspects of running free and open source software is
the ability to be able to continually tinker with your setup, limited only by
your imagination and ability.  The more you do tinker, the smaller the gap
between the former and the latter, as each small project inevitably leads you
into a deeper understanding of various aspects of your system<sup>1</sup> and
how you can customize that system to suit your exact requirements.</p>

<p>Over the last couple of days, I have been playing with
<a href="http://en.wikipedia.org/wiki/Udev" title="Wikipedia page">udev</a>, the kernel device
manager, as I was attempting to run a script once a specific
<acronym title="Universal Serial Bus">USB</acronym> drive was plugged in. It
turns out, as is so often the case, that udev is only <em>part</em> of the
picture…</p>

<p>As both my work and personal laptops have relatively small
<acronym title="Solid State Drives">SSDs</acronym>, I carry around
<a href="http://alpha.libre.fm/user/jasonwryan/" title="Libre.fm profile">my music</a>
on a 1TB external drive. As the drive only contains <span class="file">.flac</span>
files, I wanted to automate the process of <code>rsync</code>’ing music from my desktop to
the drive and, for the laptops, repopulating the symlinks to
<span class="file">~/Music/</span> when the drive was plugged in.</p>

<p>My first thought was a rule in <span class="file">/etc/udev/rules.d/</span>,
using <code>RUN+=</code>. There are any number of blog posts espousing this approach and,
as I quickly discovered, they are <em>all</em> wrong. The problem with using this key is
that, as the <code>man</code> page makes clear, it is not designed for long running
programs:</p>

<blockquote><p>This can only be used for very short-running foreground tasks. Running an event process for a long period of time may block all further events for this or a dependent device.</p><p>Starting daemons or other long running processes is not appropriate for udev; the forked processes, detached or not, will be unconditionally killed after the event handling has finished.</p><footer><strong>udev manual</strong> <cite><a href='http://www.freedesktop.org/software/systemd/man/udev.html'>www.freedesktop.org/software/&hellip;</a></cite></footer></blockquote>


<p>The problem, as it manifest for me, was the drive would be blocked from
mounting until <em>after</em> the script had run, meaning <code>rsync</code> or my symlinks would
have no target.  There are various “workarounds” on the web for this, including
using <em>two</em> scripts, one to trigger the other<sup>2</sup>. Even for me, this
seemed like a
<a href="http://en.wikipedia.org/wiki/Pyrrhic_victory" title="Wikipedia entry">Pyrrhic victory</a>.</p>

<p>The correct way to do this, as I found once I uncovered
<a href="https://bbs.archlinux.org/viewtopic.php?id=149419" title="Arch BBS">this thread</a>
on the Arch boards where WonderWoofy and 65kid helpfully pieced it together, is
to use <code>SYSTEMD_WANTS</code>.  As it is described in the manual:</p>

<blockquote><p>THE UDEV DATABASE<br/>  The settings of device units may either be configured via unit files, or directly from the udev database (which is recommended). The following udev properties are understood by systemd:</p><p>  SYSTEMD_WANTS=<br/>  Adds dependencies of type Wants from this unit to all listed units. This may be used to activate arbitrary units, when a specific device becomes available. Note that this and the other tags are not taken into account unless the device is tagged with the &#8220;systemd&#8221; string in the udev database, because otherwise the device is not exposed as systemd unit.</p><footer><strong>man systemd.device</strong> <cite><a href='http://www.freedesktop.org/software/systemd/man/systemd.device.html'>www.freedesktop.org/software/&hellip;</a></cite></footer></blockquote>


<p>So, I edited <span class="file">/etc/udev/rules.d/90-usb-music.rules</span> to
remove the <code>RUN+=</code> key, using a systemd service file instead, like so<sup>3</sup>:</p>

<figure class='code'> <div class="highlight"><pre><code class='sh'><span class='line'><span class="nv">SUBSYSTEMS</span><span class="o">==</span><span class="s2">&quot;usb&quot;</span>, ATTRS<span class="o">{</span>idProduct<span class="o">}==</span><span class="s2">&quot;1905&quot;</span>, <span class="nv">ACTION</span><span class="o">==</span><span class="s2">&quot;add&quot;</span>, ENV<span class="o">{</span>SYSTEMD_WANTS<span class="o">}==</span><span class="s2">&quot;upmusic.service&quot;</span>
</span></code></pre></div></figure>


<p>And then wrote the corresponding service file to have systemd hand off to the bash script:</p>

<figure class='code'><figcaption><span>/usr/lib/systemd/system/upmusic.service </span></figcaption>
 <div class="highlight"><pre><code class='sh'><span class='line'><span class="o">[</span>Unit<span class="o">]</span>
</span><span class='line'><span class="nv">Description</span><span class="o">=</span>Update music links from Apollo
</span><span class='line'><span class="nv">Requires</span><span class="o">=</span>media-Apollo.mount
</span><span class='line'><span class="nv">After</span><span class="o">=</span>media-Apollo.mount
</span><span class='line'>
</span><span class='line'><span class="o">[</span>Service<span class="o">]</span>
</span><span class='line'><span class="nv">ExecStart</span><span class="o">=</span>/home/jason/Scripts/upmusic
</span><span class='line'>
</span><span class='line'><span class="o">[</span>Install<span class="o">]</span>
</span><span class='line'><span class="nv">WantedBy</span><span class="o">=</span>media-Apollo.mount
</span></code></pre></div></figure>


<p>As I mentioned in my post on my
<a href="http://jasonwryan.com/blog/2013/10/28/dismount/" title="Unmount USB drives…">simple unmounting script</a>,
I use a naming convention for all my USB drives. In this case, my music is stored on Apollo, and
it is auto-mounted with
<a href="https://wiki.archlinux.org/index.php/Udiskie" title="Arch wiki page">udiskie</a>. In the
service file, systemd uses a hyphen instead of a forward slash, so the correct
designation is <code>media-Apollo.mount</code>.</p>

<p>Then it is just a matter of enabling the service with <code>systemctl enable upmusic</code> and,
whenever Apollo is plugged in to either my desktop of laptop, the appropriate
script will run and either update the files on Apollo or the symlinks on one of the
laptops.</p>

<h4>Notes</h4>

<ol>
<li>This shouldn&#8217;t be taken as any sort of claim of expertise or deep
understanding of this, or any other, part of my system. See below.</li>
<li>Which is why you should never trust anything written by bloggers…</li>
<li>The definitive reference for udev rules remains
<a href="http://www.reactivated.net/writing_udev_rules.html" title="Daniel Drake's page">Writing udev rules</a></li>
</ol>


<p>Creative Commons image on Flickr by <a href="http://www.flickr.com/photos/jacobgarcia/2550146/" title="Licensed CC by Jacob Garcia">Jacob Garcia</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ad Blocking with Hostsblock]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/12/28/hostsblock/"/>
    <updated>2013-12-28T10:09:00+13:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/12/28/hostsblock</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/ad_free.png" title="Flickr CC Image" >
The relentless commercialization of traditional holidays, not just the December
variety but all of them now, means that what was ostensibly an occasion for
celebrating your particular flavour of $deity, pagan ritual or just an
opportunity to reconnect with your wider family, has been co-opted to the
worship of the most pernicious of all cults, consumerism.</p>

<p>Concomitant with this is the increasing corporatisation of the Internet; the
deliberate and seemingly ineluctable effort by a relatively small number of
global interests to turn most of the Internet into something more like cable
television. As someone who has not lived with a television for decades
precisely because I don&#8217;t want to live in a
<a href="http://en.wikipedia.org/wiki/Operant_conditioning_chamber" title="Wikipedia page">Skinner box</a>
that is solely designed to condition me to compliantly purchase more product,
I find this rankly offensive (in the sense of morally repugnant as well as a
coordinated and remorseless assault).</p>

<p>With the escalation of both the level and nauseating intensity of advertising
around the “holiday season” and the almost hysterical exhortations to purchase
more happiness, I decided that the one thing that I would be really thankful for
this Christmas was better ad blocking.</p>

<p>I had been using
<a href="https://wiki.archlinux.org/index.php/Privoxy" title="Arch wiki entry">Privoxy</a> and an
<acronym title="Arch User Repository">AUR</acronym> script,
<a href="https://aur.archlinux.org/packages/blocklist-to-privoxy/?ID=63431" title="AUR page">blocklist-to-privoxy</a>
but I was still experiencing a lot of ads sneaking through (particularly local
ones) and some unintended side effects of using Privoxy for this job, so I
decide to give Jake VanderKolk&#8217;s
<a href="http://gaenserich.github.io/hostsblock/" title="Homepage for Hostsblock">Hostsblock</a>
a shot.</p>

<p>I went with the basic, entry level setup:
<a href="https://aur.archlinux.org/packages/kwakd/" title="AUR page">kwakd</a> for serving blank
<acronym title="HyperText Markup Language">HTML</acronym> in place of ads and
<a href="https://aur.archlinux.org/packages.php?ID=58976" title="AUR package">hostsblock</a> to
write to my <span class="file">/etc/hosts</span>. I didn&#8217;t see the need for
<a href="https://wiki.archlinux.org/index.php/Dnsmasq" title="Arch Wiki page">dnsmasq</a> and,
after a week or so or using it haven&#8217;t seen the need to revisit that decision.</p>

<p>Suffice to say, it is working brilliantly. Where once web pages were festooned
with garish advertisements promising me ripped abdominals, tropical holidays and the
lasting serenity that only Apple products can really truly deliver, I now have
<a href="http://miromiro.com/Blog-images/herald.png" title="Screenshot of the local rag…">glorious whitespace</a></p>

<p>There are a couple of other factors to consider with Hostsblock. There is a very
simple command line interface for managing black and white listing of websites,
and the various “content distribution networks” that infest most commercial
sites like fleas. You can easily allow advertisements on or from sites and
organizations that you want to support, while forever muting the inane drivel
from the likes of Failbook <em>et al</em>.</p>

<p>Installation and setup are very straightforward, with simple instructions on the
<a href="http://gaenserich.github.io/hostsblock/" title="Two or three steps, max…">Hostsblock site</a>.
There is also an active thread on the
<a href="https://bbs.archlinux.org/viewtopic.php?id=139784" title="Arch forum thread">Arch boards</a>
where Jake and a couple of others are extremely helpful.</p>

<p>If you are feeling listless, run-down and lacking in energy, why not try
Hostsblock? It will make your web pages brighter, speed up your page loads,
protect your privacy and make you insanely popular. Try Hostsblock today!</p>

<h4>Notes</h4>

<p>ad free, a Creative Commons image by
<a href="http://www.flickr.com/photos/louisa_catlover/2875951548/">Louisa Billeter on Flickr</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[BitTorrent Sync's API]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/11/14/api/"/>
    <updated>2013-11-14T09:51:00+13:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/11/14/api</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/sync.png" title="Bittorrent logo" >
I have
<a href="http://jasonwryan.com/blog/2013/03/16/sync/" title="Post on the Alpha release">written previously</a>
about
<a href="http://www.bittorrent.com/sync" title="Sync webpage">BitTorrent Sync</a>, the encrypted
file syncing application that uses the bittorrent protocol to sync your data
over your <acronym title="Local Area Network">LAN</acronym>, or over the Internet,
using <a href="https://en.wikipedia.org/wiki/Peer_to_peer" title="Wikipedia page">P2P technology</a>.
I have been using it since early this year as a replacement for
dropbox.<sup>1</sup></p>

<p>At the beginning of this month, BitTorrent unveiled the
<a href="http://blog.bittorrent.com/2013/11/05/bittorrent-sync-beta-api-now-available-to-developers/" title="Sync blog announcement">Beta API</a>
for developers (meaning you have to tell them what you plan to do in order to
be issued a key). After some equivocation, I signed up with the rather flimsy
excuse of “writing a shell wrapper for the command line” and found, to my
chagrin, a key in my inbox the next morning.</p>

<p>This proved to be something of an unwelcome arrival. In theory, I was excited
about having access to a tool to query the Sync application. One of the nodes is
on my
<a href="http://jasonwryan.com/blog/2013/06/29/raspberry/" title="Post on setting up a torrent box">headless Raspberry Pi</a>
and the idea of being able to issue a command from my laptop to ascertain what
was going on in the Pi&#8217;s synced folders was (and is) a tremendously attractive
one.</p>

<p>However, now that I was in
possession of the key, I felt morally obliged to do something with it. The
problem with this realization was that I had no idea how to work with an
<acronym title="Application Program Interface">API</acronym>, let alone writing
a script to accomplish my purported goal.</p>

<p>After spending some time looking at
<a href="http://www.bittorrent.com/sync/developers/api" title="Such as it is…">the documentation</a>,
and buoyed by the optimism of ignorance, I decided to make good on my promise.
My first attempt sort of worked, but was hampered as much by a serious
conceptual flaw as it was by poor implementation. I decided, in spite of any number
of Stack Overflow posts warning expressly not to do this, to use <code>awk</code> to parse
the <a href="http://www.json.org/" title="JSON homepage">JSON data</a><sup>2</sup>. This was what I would
euphemistically describe as a “learning opportunity.” The result is preserved
for posterity in my <a href="https://bitbucket.org/jasonwryan/shiv/commits/16c9dee17f097e83fb325e303d867e6fda488992?at=default" title="Bit of a trainwreck, but you have to start somewhere…">bitbucket repo</a>
(for the completists)…</p>

<p>At this point, I was fortunate that Earnestly in #archlinux introduced me to
keenerd&#8217;s purpose built tool, <a href="http://kmkeen.com/jshon/" title="Kyle's site: visit it. Now.">Jshon</a>.
And by “introduced” I mean generously (and patiently) talked me through how it
worked and how I could use it with the Sync API to achieve what I was after.
After a while playing with it, there was the—inevitably belated—moment of
realization: this thing is genius! It allows you to intelligently
<em>interrogate</em> the data. Not blindly chopping at it with an increasingly complex
series of actions in <code>awk</code><sup>3</sup>; but quite directly traversing the structure and
extracting the desired elements.</p>

<p>Now I was <em>cooking</em>. Well, more to the point, I was flailing about in a smoke
filled kitchen convinced that the feeling of euphoria was inspiration—not imminent
asphyxiation. Once again, Earnestly&#8217;s patience and bash skills were put to good effect.
The resulting script,
<a href="https://bitbucket.org/jasonwryan/shiv/src/tip/Scripts/syncstat" title="In bitbucket">syncstat</a>,
is undeniably a triumph of his good ideas over my own poor execution. In other
words, the fact that it works so well is testament to his ability, but any and
all faults are mine alone<sup>4</sup>.</p>

<p>And it does work. It only requires
<a href="https://www.archlinux.org/packages/?sort=&amp;q=jshon" title="Arch package db">Jshon</a>
(which you will already have installed because you use
<a href="http://jasonwryan.com/blog/2012/03/09/aurphan/" title="My post on this great utility">aurphan, right?</a>)
and a file with your synced folders and their respective secrets on each line<sup>5</sup>, like so:</p>

<figure class='code'> <div class="highlight"><pre><code class='sh'><span class='line'>directory1 YourRe@llyTr1cky53cr3t
</span><span class='line'>directory2 H0p3fu11yY0uG3tTh31d3@
</span></code></pre></div></figure>


<p>The functionality in the script is limited at this stage to just querying the
application; I wasn&#8217;t interested in pushing changes at this point. So you can
access the version of the currently installed Syncapp, upload and download
speeds, the size of synced folders and list all of their contents.</p>

<p>It is a beta release, so the odd bug is to be expected. Overall, though, the API is
a welcome addition to what is a great application. If you have an API key, add
it to your <span class="file">sync.conf</span>,
<a href="https://bitbucket.org/jasonwryan/shiv/src/tip/Scripts/syncstat" title="On bitbucket">grab the script</a>
and give it a whirl. Undoubtedly, over the coming weeks more polished versions
will emerge in “proper” languages, but for the time being this does exactly what
I need.</p>

<h4>Notes</h4>

<ol>
<li>Yes, I would much prefer to use an open source tool to accomplish the same
thing but I haven&#8217;t found anything comparable that is this good to date…</li>
<li>In what I imagine is a complete coincidence, the JSON logo is uncannily
similar to the initial (and much better, I thought) Sync logo, as seen on
<a href="http://jasonwryan.com/blog/2013/03/16/sync/">my original post</a>.</li>
<li>This is not intended as a slight on <code>awk</code>; which I am undoubtedly
<a href="http://jasonwryan.com/blog/2013/09/15/awking/">fond of</a>, but rather the
limits of my ability with that language.</li>
<li>I am also indebted to Scott (firecat53) for testing and providing helpful
feedback on the early versions of the script.</li>
<li>It is worth noting that in the <code>$json</code> variable, I pass <code>curl</code> the -<code>n</code> option,
which means it reads my credentials from <span class="file">$HOME/.netrc</span>.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Simple Unmounting]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/10/28/dismount/"/>
    <updated>2013-10-28T15:29:00+13:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/10/28/dismount</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/dismount.jpg" title="Creative Commons image" >
For those people that prefer to forego the full blown
<acronym title="Desktop Environment">DE</acronym> and—instead of all the
“convenience” that this sort of setup offers—piece together their setup from a
variety of different tools and knit it all together with some scripting,
automounting external drives is, notwithstanding the inexplicable number of
posts to the forums to the contrary, incredibly straightforward with
<a href="https://wiki.archlinux.org/index.php/Udev#Udisks" title="Arch Wiki page on Udev">udisks</a>.
My approach in this respect is to use
<a href="https://wiki.archlinux.org/index.php/Udiskie" title="Wiki page">udiskie</a>; it is
lightweight, unobtrusive, configurable and foolproof, as far as I can tell.</p>

<p>Where I have found a small gap, or more a minor irritation really, is with
unmounting devices. <code>udiskie-umount /media/MY_USB_DRIVE</code> works just fine, but
I often have a variety of media mounted, and not just standard
<acronym title="Universal Serial Bus">USB</acronym> drives. At work, for
example, it is not uncommon for me to have mounted under
<span class="file">/media</span> any or all of the following:</p>

<ul>
<li>A USB drive containing all of my music</li>
<li>An encrypted volume mounted with
<a href="http://jasonwryan.com/blog/2013/01/10/truecrypt/" title="My post on replacing TrueCrypt">tcplay</a>
shared via <a href="http://jasonwryan.com/blog/2013/03/16/sync/" title="Another postof mine…">Bittorrent Sync</a></li>
<li>A <acronym title="Common Internet File System">CIFS</acronym> share</li>
<li>An <acronym title="Network File System">NFS</acronym> share or an
<acronym title="SSH Filesystem">SSHFS</acronym> mount.</li>
</ul>


<p>In a couple of these cases, I don&#8217;t want to—or can&#8217;t—just <code>umount</code> them with
<code>udiskie</code>; they require a different approach. To facilitate this, I have adopted
a simple approach: I use a standard naming convention for all external media
or their mountpoints. When I first buy a USB drive, I give it a meaningful name,
beginning with an uppercase letter, as this won&#8217;t clash with any of my internal
drives and it happily accommodates drives from other operating systems. So:</p>

<figure class='code'> <div class="highlight"><pre><code class='sh'><span class='line'>sudo dosfslabel /dev/sdc1 EightBall
</span></code></pre></div></figure>


<p>sets up a new 8GB drive I found in the schwag bag at the conference I attended
last week.</p>

<p>Now that all external media are predictably named, it is just a matter of
writing a script that checks how many are mounted, presents a menu if there is
more than one, and unmounts the respective device correctly:</p>

<figure class='code'><figcaption><span>dismount </span></figcaption>
 <div class="highlight"><pre><code class='sh'><span class='line'><span class="c">#!/usr/bin/env bash</span>
</span><span class='line'><span class="c"># unmount USB drives</span>
</span><span class='line'>
</span><span class='line'><span class="nv">target</span><span class="o">=(</span> <span class="k">$(</span>awk <span class="s1">&#39;/media\/[\^A-Z]/ {print $3}&#39;</span> &lt;<span class="o">(</span>mount<span class="k">)</span><span class="o">)</span> <span class="o">)</span>
</span><span class='line'><span class="nv">shares</span><span class="o">=(</span>Scout Sentinel<span class="o">)</span>
</span><span class='line'>
</span><span class='line'>checkbusy<span class="o">()</span> <span class="o">{</span>
</span><span class='line'>  grep <span class="s2">&quot;PID&quot;</span> &lt;<span class="o">(</span>lsof +d <span class="s2">&quot;$target&quot;</span> &amp;&gt;/dev/null<span class="o">)</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">[[</span> <span class="nv">$?</span> -eq 0 <span class="o">]]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">    </span><span class="nb">printf</span> <span class="s2">&quot;%s\n&quot;</span> <span class="s2">&quot;${target##*/} busy…&quot;</span>
</span><span class='line'>    <span class="nb">exit </span>1
</span><span class='line'>  <span class="k">fi</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'>exstatus<span class="o">()</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">if</span> <span class="o">[[</span> <span class="nv">$?</span> -eq 0 <span class="o">]]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">    </span><span class="nb">printf</span> <span class="s2">&quot;%s\n&quot;</span> <span class="s2">&quot;${target##*/} unmounted…&quot;</span>
</span><span class='line'>  <span class="k">else</span>
</span><span class='line'><span class="k">    </span><span class="nb">printf</span> <span class="s2">&quot;%s\n&quot;</span> <span class="s2">&quot;Failed to unmount.&quot;</span>
</span><span class='line'>  <span class="k">fi</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="c"># check for multiple devices</span>
</span><span class='line'><span class="k">if</span> <span class="o">((</span> <span class="s2">&quot;${#target[@]}&quot;</span> &gt; 1 <span class="o">))</span>; <span class="k">then</span>
</span><span class='line'><span class="k">  </span><span class="nv">PS3</span><span class="o">=</span><span class="s2">&quot;Select your device to unmount: &quot;</span>
</span><span class='line'>  <span class="nb">printf</span> <span class="s2">&quot;%s\n&quot;</span> <span class="s2">&quot;There are ${#target[@]} devices mounted&quot;</span>
</span><span class='line'>  <span class="k">select </span>dev in <span class="s2">&quot;${target[@]}&quot;</span>; <span class="k">do</span>
</span><span class='line'><span class="k">    </span><span class="nv">target</span><span class="o">=</span><span class="s2">&quot;$dev&quot;</span>
</span><span class='line'>    <span class="nb">break</span>
</span><span class='line'><span class="nb">  </span><span class="k">done</span>
</span><span class='line'><span class="k">fi</span>
</span><span class='line'>
</span><span class='line'><span class="c"># check for share</span>
</span><span class='line'><span class="k">for </span>drive in <span class="s2">&quot;${shares[@]}&quot;</span>; <span class="k">do</span>
</span><span class='line'><span class="k">  if</span> <span class="o">[[</span> <span class="s2">&quot;$drive&quot;</span> <span class="o">=</span>~ <span class="s2">&quot;${target##*/}&quot;</span> <span class="o">]]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">    </span><span class="nv">share</span><span class="o">=</span><span class="s2">&quot;$drive&quot;</span>
</span><span class='line'>  <span class="k">fi</span>
</span><span class='line'><span class="k">done</span>
</span><span class='line'>
</span><span class='line'><span class="c"># options per filesystem</span>
</span><span class='line'><span class="k">if</span> <span class="o">[[</span> -n <span class="s2">&quot;$target&quot;</span> <span class="o">]]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">  for </span>drive in <span class="s2">&quot;${shares[@]}&quot;</span>; <span class="k">do</span>
</span><span class='line'><span class="k">    if</span> <span class="o">[[</span> <span class="s2">&quot;$drive&quot;</span> <span class="o">=</span> <span class="s2">&quot;${target##*/}&quot;</span> <span class="o">&amp;&amp;</span> <span class="s2">&quot;${target##*/}&quot;</span> <span class="o">=</span> Safebox <span class="o">]]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">      </span><span class="nv">cmd</span><span class="o">=</span><span class="k">$(</span>sudo safebox close<span class="k">)</span>
</span><span class='line'>    <span class="k">elif</span> <span class="o">[[</span> <span class="s2">&quot;$drive&quot;</span> <span class="o">=</span> <span class="s2">&quot;${target##*/}&quot;</span> <span class="o">]]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">      </span><span class="nv">cmd</span><span class="o">=</span><span class="k">$(</span>sudo umount <span class="s2">&quot;$target&quot;</span><span class="k">)</span>
</span><span class='line'>    <span class="k">else</span>
</span><span class='line'><span class="k">      </span><span class="nv">cmd</span><span class="o">=</span><span class="k">$(</span>udiskie-umount -d <span class="s2">&quot;$target&quot;</span> &amp;&gt;/dev/null<span class="k">)</span>
</span><span class='line'>    <span class="k">fi</span>
</span><span class='line'><span class="k">  done</span>
</span><span class='line'><span class="c"># do it</span>
</span><span class='line'>checkbusy
</span><span class='line'><span class="nv">$cmd</span>
</span><span class='line'>exstatus
</span><span class='line'><span class="k">else</span>
</span><span class='line'><span class="k">  </span><span class="nb">printf</span> <span class="s2">&quot;%s\n&quot;</span> <span class="s2">&quot;No drive mounted!&quot;</span>
</span><span class='line'><span class="k">fi</span>
</span><span class='line'>
</span><span class='line'><span class="c"># vim:set ts=2 sts=2 sw=2 et:</span>
</span></code></pre></div></figure>


<p>Now, no matter the number or type of devices I currently have mounted, I can
unmount them by typing <code>dismount</code> and choosing the appropriate drive via the
<code>select</code> menu. Simple, but satisfying. The script is in my
<a href="https://bitbucket.org/jasonwryan/centurion/src/tip/Scripts/dismount%20'Grab%20it!">bitbucket repo</a></p>

<h4>Notes</h4>

<p>Creative Commons image, Dismount, by
<a href="http://www.flickr.com/photos/chrisinplymouth/3659964278/">Chris</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Managing modules with Awk]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/09/15/awking/"/>
    <updated>2013-09-15T09:23:00+12:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/09/15/awking</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/awk.jpg" title="The Great Auk" >
This is an addendum to my two previous posts on
<a href="http://jasonwryan.com/blog/2013/08/03/kernels/" title="The first post">compiling kernels</a>
and <a href="http://jasonwryan.com/blog/2013/08/24/automating-kernels/" title="The folow up">automating the process</a>.
In the first of those posts I wrote about a wonderful tool to track the modules
necessary for building a custom kernel with <code>make localmodconfig</code>, graysky&#8217;s
<a href="https://github.com/graysky2/modprobed_db" title="Github repo">modprobed_db</a>. A simple
bash script, <code>modprobed_db</code> allows you to build up an array of modules and—as
the name suggests—<code>modprobe</code> all of them prior to compilation.</p>

<p>I forked it on github and started to play around with the script (mostly because
I am slightly <acronym title="Obsessive Compulsive Disorder">OCD</acronym> about
constructions
<a href="https://github.com/graysky2/modprobed_db/blob/master/common/modprobed_db#L62" title="awk pipeline">like this</a>:</p>

<figure class='code'><figcaption><span>modprobed_db lines 62-63 </span></figcaption>
 <div class="highlight"><pre><code class='sh'><span class='line'>cat /proc/modules | awk <span class="s1">&#39;{print $1}&#39;</span> | sort -k 1,1 | <span class="se">\</span>
</span><span class='line'>  grep -Ev <span class="s2">&quot;$(echo ${IGNORE[*]} | sed -e &#39;s/^/^(/&#39; -e &#39;s/ /|/g&#39; -e &#39;s/$/)$/&#39;)&quot;</span> <span class="se">\</span>
</span><span class='line'>  &gt;/tmp/.inmem
</span></code></pre></div></figure>


<p><a href="https://github.com/jasonwryan/modprobed_db/blob/jwr/common/modprobed_db" title="My branch">After hacking a while</a>,
I started to realize that the venerable UNIX programme
<a href="http://www.gnu.org/software/gawk/manual/" title="gawk manual on GNU site">Awk</a>
 would, in many ways, be a better tool for this job. Essentially, we want to
 manage three lists: the modules in <span class="file">/proc/modules</span>, a
 list of modules to ignore, and the master list of all modules required prior to
 compilation. This seems perfectly suited to Awk.</p>

<p> So, in the interests of learning Awk, I decided to rewrite the required
 functionality (or, more correctly, the subset that I required) in this
 language. This wasn&#8217;t a straightforward task for me. I got stuck a couple of
 times and, as I work in a building full of
 <a href="http://catalyst.net.nz" title="Catalyst website">neckbeards</a>, I thought I could ask
 for a couple of pointers. To my surprise, no-one I asked seemed interested in
 Awk. Typical responses were along the lines of “just use Perl.”</p>

<p> Aside from not knowing any
 <a href="http://www.perl.org/" title="Perl homepage">Perl</a>, and being unlikely to learn any
 in the immediate future, I was bemused by the notion that none of these skilled
 developers rated Awk as a language worth knowing. One of the #awk FAQ&#8217;s
 specifically addresses this:
 <a href="http://awk.freeshell.org/Frequently_Asked_Questions#toc14" title="#awk FAQs">Why would anyone still use awk instead of perl?</a>
 The quote by Tom Christiansen is worth repeating here:</p>

<p> <blockquote><p>Awk is a venerable, powerful, elegant, and simple tool that everyone should know. Perl is a superset and child of awk, but has much more power that comes at expense of sacrificing some of that simplicity.</p></blockquote></p>

<p>In a happy coincidence, this
<a href="http://unix.stackexchange.com/questions/90489/compare-two-files-with-first-column-and-remove-duplicate-row-from-2nd-file-in-sh/90490#90490" title="Comparing two files">question on Unix &amp; Linux SE</a>
showed up just as I was completing my script and it neatly illustrates (to my
unututored eye, anyway) an example of a typical situation where Awk&#8217;s strengths
make it a better approach than Perl.</p>

<p>In any event, my rewriting of <code>modprobed_db</code> in Awk<sup>1</sup> resulted in this:</p>

<figure class='code'><figcaption><span>awkmodules </span></figcaption>
 <div class="highlight"><pre><code class='awk'><span class='line'><span class="c1">#!/usr/bin/awk -f</span>
</span><span class='line'><span class="c1"># script to manage modules for kernel builds</span>
</span><span class='line'>
</span><span class='line'><span class="nx">BEGIN</span> <span class="p">{</span> <span class="nx">dbfile</span> <span class="o">=</span> <span class="nb">ARGV</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="kd">function</span> <span class="nx">red</span><span class="p">(</span><span class="nx">s</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="kr">printf</span> <span class="s2">&quot;\033[1;31m&quot;</span> <span class="nx">s</span> <span class="s2">&quot;\033[0m &quot;</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="c1"># read in the array</span>
</span><span class='line'><span class="nb">FILENAME</span> <span class="o">!=</span> <span class="nb">ARGV</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">modlist</span><span class="p">[</span><span class="o">$</span><span class="mi">1</span><span class="p">]</span><span class="o">++</span><span class="p">;</span> <span class="kr">next</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="c1"># check for ignored modules</span>
</span><span class='line'><span class="o">!</span><span class="nx">modlist</span><span class="p">[</span><span class="o">$</span><span class="mi">1</span><span class="p">]</span><span class="o">++</span> <span class="p">{</span>
</span><span class='line'>  <span class="kr">print</span> <span class="o">$</span><span class="mi">1</span> <span class="o">&gt;&gt;</span> <span class="nx">dbfile</span>
</span><span class='line'>  <span class="kr">close</span><span class="p">(</span><span class="nx">dbfile</span><span class="p">)</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="p">{</span>
</span><span class='line'><span class="c1"># modprobe modules</span>
</span><span class='line'><span class="k">if</span> <span class="p">(</span><span class="nx">p</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">modload</span><span class="o">=</span><span class="s2">&quot;sudo modprobe -a $(&lt;&quot;</span><span class="nx">dbfile</span><span class="s2">&quot;)&quot;</span>
</span><span class='line'>  <span class="kr">system</span><span class="p">(</span><span class="nx">modload</span><span class="p">)</span>
</span><span class='line'>  <span class="kr">close</span><span class="p">(</span><span class="nx">modload</span><span class="p">)</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="p">{</span>
</span><span class='line'><span class="c1"># update module count</span>
</span><span class='line'><span class="k">if</span> <span class="p">(</span> <span class="kr">getline</span> <span class="o">&lt;</span> <span class="nx">dbfile</span> <span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="nx">count</span><span class="o">++</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="nx">END</span> <span class="p">{</span>
</span><span class='line'>  <span class="kr">print</span> <span class="nx">red</span><span class="p">(</span><span class="nx">count</span><span class="p">)</span> <span class="s2">&quot;modules listed.&quot;</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="c1"># vim:set ts=2 sts=2 sw=2 et:</span>
</span></code></pre></div></figure>


<p>Just prior to compiling a kernel, I can invoke this script with (the admittedly
rather ungainly line):</p>

<figure class='code'> <div class="highlight"><pre><code class='sh'><span class='line'>awkmodules <span class="nv">p</span><span class="o">=</span>1 .config/kmod_db/ignored .config/kmod_db/modules_db /proc/modules
</span></code></pre></div></figure>


<p>It does work, but I don&#8217;t claim that it is either idiomatic or attractive. The
use of <code>getline</code> to update the module count strikes me as especially kludgy but
I haven&#8217;t been able to think of a more correct way to handle it.</p>

<p>Incidentally, the gawk manual<sup>2</sup>,
<a href="http://www.gnu.org/software/gawk/manual/" title="GNU goodness">Gawk: Effective AWK Programming</a>
has only just been updated<sup>3</sup> so Awk is, unlike it&#8217;s homonym, clearly
alive and well.</p>

<h4>Notes</h4>

<ol>
<li>In my <a href="https://bitbucket.org/jasonwryan/shiv/src/tip/Scripts/awkmodules">bitbucket repo</a>.</li>
<li>The number of variants of <code>awk</code> is as much a delight as it is perplexing…</li>
<li>May, 2013</li>
</ol>


<p>Public Domain image of the Great Auk by John James Audubon, from his book
<a href="https://en.wikipedia.org/wiki/File:PinguinusImpennus.jpg">The Birds of America</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Automating Kernel Builds]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/08/24/automating-kernels/"/>
    <updated>2013-08-24T10:30:00+12:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/08/24/automating-kernels</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/robot.jpg" title="I Robot" >
I posted a couple of weeks ago about
<a href="http://jasonwryan.com/blog/2013/08/03/kernels/" title="Check it if you haven't...">compiling a custom kernel</a>
using <a href="https://github.com/graysky2/modprobed_db" title="graysky's github repo">modprobed_db</a>
and at the time I talked about automating the process, essentially so that every
kernel update, be it the standard Arch kernel or the stripped down custom one,
would be a simple, streamlined process. I updated that post with
<a href="https://bitbucket.org/jasonwryan/shiv/src/tip/Build/linux-jwr/PKGBUILD" title="bitbucket repo">a PKGBUILD</a>,
which was the first step. This completes that process.</p>

<p>There is not a lot to it. A
<a href="https://bitbucket.org/jasonwryan/shiv/src/tip/Scripts/new_kernel" title="bitbucket repo">short bash wrapper</a>
that sets up the required files, updates the aforementioned PKGBUILD and then
triggers <code>makepkg</code> (providing nothing else fails). All it requires is that you
have
<a href="https://bitbucket.org/jasonwryan/shiv/src/tip/Build/linux-jwr%20'You%20guessed%20it%E2%80%A6">the necessary files</a>
in a separate directory for the script to reference and
you are set. If anything does go wrong with the new kernel, you still have the
previous working custom kernel <code>.tar.xz</code> you can reinstall, or you can of course
just boot into the vanilla Arch kernel.</p>

<figure class='code'><figcaption><span>new_kernel </span></figcaption>
 <div class="highlight"><pre><code class='bash'><span class='line'><span class="c">#!/usr/bin/env bash</span>
</span><span class='line'><span class="c"># install new kernel</span>
</span><span class='line'>
</span><span class='line'><span class="nv">vers</span><span class="o">=</span><span class="nv">$1</span>
</span><span class='line'><span class="nv">cyn</span><span class="o">=</span><span class="s1">$&#39;\e[1;36m&#39;</span>
</span><span class='line'><span class="nv">ylw</span><span class="o">=</span><span class="s1">$&#39;\e[1;33m&#39;</span>
</span><span class='line'><span class="nv">red</span><span class="o">=</span><span class="s1">$&#39;\e[1;31m&#39;</span>
</span><span class='line'><span class="nv">end</span><span class="o">=</span><span class="s1">$&#39;\e[0m&#39;</span>
</span><span class='line'>
</span><span class='line'><span class="k">if</span> <span class="o">[[</span> <span class="nv">$# </span>!<span class="o">=</span> 1 <span class="o">]]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">  </span><span class="nb">printf</span> <span class="s1">&#39;%s\n&#39;</span> <span class="s2">&quot;Usage: &quot;</span><span class="k">${</span><span class="nv">0</span><span class="p">##*/</span><span class="k">}</span><span class="s2">&quot; 3.10.8&quot;</span>
</span><span class='line'>  <span class="nb">exit </span>1
</span><span class='line'><span class="k">fi</span>
</span><span class='line'>
</span><span class='line'><span class="c"># back up last dir</span>
</span><span class='line'><span class="nb">cd</span> ~/Build
</span><span class='line'>rm -rf linux-jwr/<span class="o">{</span>pkg,src<span class="o">}</span>
</span><span class='line'>mv linux-jwr linux-<span class="k">${</span><span class="nv">vers</span><span class="p">%.*</span><span class="k">}</span>.<span class="k">$((${</span><span class="nv">vers</span><span class="p">##*.</span><span class="k">}</span> <span class="o">-</span> <span class="m">1</span><span class="k">))</span>
</span><span class='line'>
</span><span class='line'><span class="c"># set up clean files</span>
</span><span class='line'>cp -r kernel_files linux-jwr <span class="o">&amp;&amp;</span> <span class="nb">cd</span> <span class="s2">&quot;$_&quot;</span>
</span><span class='line'>
</span><span class='line'>sed -i <span class="s2">&quot;s:pkgver=[0-9].*:pkgver=${vers}:&quot;</span> PKGBUILD
</span><span class='line'><span class="nv">newvers</span><span class="o">=</span><span class="k">$(</span>awk -F<span class="o">=</span> <span class="s1">&#39;/pkgver=/ {print $2}&#39;</span> PKGBUILD<span class="k">)</span>
</span><span class='line'><span class="nb">printf</span> <span class="s1">&#39;%s\n&#39;</span> <span class="s2">&quot;Package version updated to ${ylw}$newvers${end}&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="nb">printf</span> <span class="s1">&#39;%s\n&#39;</span> <span class="s2">&quot;${cyn}Updating checksums…${end}&quot;</span>
</span><span class='line'>/usr/bin/updpkgsums
</span><span class='line'>
</span><span class='line'><span class="k">if</span> <span class="o">[[</span> <span class="nv">$?</span> -eq 0 <span class="o">]]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">  </span><span class="nb">printf</span> <span class="s1">&#39;%s\n&#39;</span> <span class="s2">&quot;${cyn}Starting build…${end}&quot;</span>
</span><span class='line'>  /usr/bin/time /usr/bin/makepkg -i
</span><span class='line'><span class="k">else</span>
</span><span class='line'><span class="k">  </span><span class="nb">printf</span> <span class="s1">&#39;%s\n&#39;</span> <span class="s2">&quot;${red}Checksum failed${end}&quot;</span>
</span><span class='line'>  <span class="nb">exit </span>1
</span><span class='line'><span class="k">fi</span>
</span><span class='line'><span class="nb">cd</span>
</span></code></pre></div></figure>


<p>That&#8217;s all there is to it. I see in my RSS reader that a new stable kernel is
available, open a terminal and run the script specifying which version to use,
for example, <code>new_kernel 3.10.9</code>.  Approximately 10 minutes later, my new kernel
is compiled and installed and I can reboot into it. Simple.</p>

<p>Undoubtedly, there is probably a cleaner way to do this, but it has worked well
for the last couple of kernels. It will probably also require tweaking for the
next series, but until that time, I am quite happy with it.</p>

<h4>Notes</h4>

<p>Flickr creative commons image
<a href="http://www.flickr.com/photos/fringley/4244586360/">My robot</a> by fringley.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Terminal Conditions]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/08/17/terminal/"/>
    <updated>2013-08-17T10:03:00+12:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/08/17/terminal</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/terminal.png" title="The Command Line" >
One of the almost inevitable consequences of using Arch Linux for any length of
time is that you will find yourself, if you weren&#8217;t already, sucked into the
gravitational vortex of the command line. The drive to continually understand,
refine and customize your setup, your workflow and the tools you use on a daily
basis will surely lead you to the point where you go from having one of those
dinky terminal emulators that scrolls down when you hit <kbd>F12</kbd>, to waking
up one day after yet another sleepless night trying to get your head around
<a href="https://en.wikipedia.org/wiki/C_%28programming_language%29" title="Wikipedia entry">C</a> or
<a href="http://www.haskell.org/haskellwiki/Haskell" title="Haskell wiki">Haskell</a>—so that
you can hack your tiling window manager to manage the dozen or so terminals
you constantly have open to your increasingly exacting specifications…</p>

<p>Once you resign yourself to this inevitability, it is a natural progression to
invest some time in setting up your terminal so that it is a pleasant, productive
environment. The first step is to choose your terminal emulator. After playing
with a few, I have settled on
<a href="http://software.schmorp.de/pkg/rxvt-unicode.html" title="Urxvt website">rxvt-unicode</a>.
Urxvt has a number of nice features, principally the ability to run in daemon
mode and, when combined with Bert Münnich&#8217;s
<a href="https://github.com/muennich/urxvt-perls/" title="Frickin genius…">urxvt-perls</a> extension,
to be able to interact with text and <acronym title="Unique Resources Locators">URLs</acronym>
with the keyboard.</p>

<p>I have also, over the last two or three months, been intermittently using
<a href="https://github.com/thestinger/termite" title="Github repo">termite</a>; the VTE-based
terminal developed by
<a href="https://github.com/thestinger" title="Github repos">Daniel Micay</a> and
<a href="https://github.com/vodik" title="Simon's Github repos">Simon Gomizelj</a>.</p>

<p>The next step is to select a colour scheme that, after long hours of peering at
the screen, won&#8217;t leave you with the eyesight of a mediæval monk. I have settled
on a dark scheme that is relatively low contrast, so works well in natural and
artificial light.<sup>1</sup> Combine this with a
<a href="https://bitbucket.org/jasonwryan/centurion/src/tip/.vim/colors" title="bitbucket repo">custom Vim colourscheme</a>
for syntax highlighting, and you have the base for a consistent aesthetic
experience in your terms.</p>

<p>The cornucopia of choice that is GNU/Linux means that in addition to choosing
your font, you also can choose how it is rendered. I use the
<a href="http://www.infinality.net/blog/" title="Infinality blog">infinality patchset</a>,
but if you are looking for a pre-rolled version I can highly recommend
bohoomil&#8217;s
<a href="http://bohoomil.cu.cc/" title="bohoomil's documentation">infinality bundle</a>.</p>

<p>The final element—and probably the most important—is the actual shell that you
will run in your terminals.
<a href="http://www.gnu.org/software/bash/bash.html" title="GNU bash page">Bash</a> is installed
everywhere (or, more correctly, everywhere that matters), so that is a solid choice.
If you are looking for a <em>lot</em> more power and flexibility, then you want
<a href="http://www.zsh.org/" title="Zsh home">Zsh</a> (with the
<a href="https://github.com/zsh-users/zsh-syntax-highlighting" title="Github repo">syntax highlights</a>
plugin).</p>

<p>If, on the other hand, you are the sort of person with tribal piercings
and a fixie, you might want to look at
<a href="http://www.tcsh.org/" title="Their website says it all, really…">tcsh</a>, or even
<a href="https://en.wikipedia.org/wiki/C_shell" title="Wikipedia page">csh</a><sup>2</sup>.</p>

<p>Customizing your shell can, in this context, be extended to practically Escheresque
extremes. The prompt, particularly in Zsh, can print relevant information,
helpfully colour coded; but it can also metastasize into a bloated ratmangle of
unicode, complete with git branches, the weather in four different timezones and
random <a href="https://en.wikipedia.org/wiki/Fortune_%28Unix%29" title="Wikipedia entry">fortunes</a>.
If, through some inexplicable turn of events, you find yourself staring at
something like this, it is time to seek help. Urgently.</p>

<p>For Zsh, I have the hostname (to avoid confusion when SSH&#8217;ing between machines,
the current working directory and, if the exit status is anything other than <code>0</code>
for the last command, that status is appended.</p>

<p>There is one other important choice to make in your shell: to run it in emacs
mode (the default) or vi-mode. This decision says as much about your competence
as it does about your overall contribution to the gene pool, so consider it carefully.
I have previously expressed my
<a href="http://jasonwryan.com/blog/2011/12/01/readline/" title="Blog post on same">preference for vi-mode</a>,
and using Zsh (which doesn&#8217;t use readline) has just entrenched that view for me.</p>

<p>Putting it all together, you end up with an interface that is as attractive to
work with as it is powerful. You have syntax highlighting, command completion
(and with Zsh, impressive correction), coloured URLs that
can be activated with the keyboard, the ability to copy and paste between
terminals and into documents or browsers, configurable keybinds, aliases and
functions limited only by your imagination and the threshold of your indolence.</p>

<p><img class="center" src="http://miromiro.com/Blog-images/terms.png"></p>

<p>One final recommendation: consider using a terminal multiplexer like tmux to
manage your terminal sessions. I have posted quite a bit about it
<a href="http://jasonwryan.com/blog/categories/tmux/" title="tmux posts">in the past</a> and it
continues to be a mainstay of my working environment. The
<a href="https://wiki.archlinux.org" title="THE wiki">Arch Wiki</a>, naturally,
has some very detailed pages on each and every aspect of using the terminal.
All of my configs are available in my bitbucket repositories:
<a href="http://bitbucket.jasonwryan.com/" title="Help yourself…">bitbucket.jasonwryan.com</a>.</p>

<h4>Notes</h4>

<ol>
<li>My dark colour scheme is in my
<a href="https://bitbucket.org/jasonwryan/centurion/src/tip/.colours/dark">bitbucket repo</a>.</li>
<li><a href="http://www.grymoire.com/Unix/CshTop10.txt" title="Reasons not to use csh">Then again…</a></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Compiling Kernels]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/08/03/kernels/"/>
    <updated>2013-08-03T09:24:00+12:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/08/03/kernels</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/kernel.jpg" title="Kernels on Flickr" >
While chasing edits on the Arch Wiki a couple of weeks ago, I stumbled upon
this page:
<a href="https://wiki.archlinux.org/index.php/Kernels/Compilation/Traditional" title="What it says on the tin…">Kernels/Compilation/Traditional</a>;
fortuitously, it transpired. For it piqued my interest sufficiently for me to
try my hand at compiling my own kernel, and—after half a dozen attempts at
getting it right—I had no sooner switched to my custom built kernel as the
default in my boot manager when 3.10.2 landed in [testing] and would not boot.
<a href="https://bbs.archlinux.org/viewtopic.php?id=167090" title="Forum thread">At all</a>.</p>

<p>I still have no idea why 3.10.2 would do nothing other than fail silently, but
the convenience of having another kernel to switch to without needing a rescue
image or any other panicked interventions immediately won me over. In the years
that I have used Arch, this was my
<a href="http://jasonwryan.com/blog/2012/07/19/breakage/" title="Post on the Myth of Breakage">first near brush</a>
with an unbootable system<sup>1</sup> and the small amount of effort required to
mitigate this risk with a custom or alternate kernel seems a smart investment to
me at this point.<sup>2</sup></p>

<p>The documentation on the wiki is both comprehensive and easy to follow. The
lessons I learned between kernels zero and three or four were mostly around
ensuring the correct modules were configured into the build. One surefire way to
make this a tedious and laborious process, should you be so inclined, is to
blindly enable and disable settings in <code>menuconfig</code>.</p>

<p>Around about the time of the fourth failed build (well, the builds were working
but the kernel wasn&#8217;t booting or was booting with missing functionality), I
decided to switch approaches and go down the <code>localmodconfig</code> route. This, for
someone with my limited experience with this aspect of GNU/Linux, was in
retrospect a decision I should have made sooner.</p>

<p>First, I started with <span class="file">streamline_config.pl</span>, a helpful
script that allows you to create a <span class="file">.config</span> file
containing only those modules necessary to your currently running
kernel<sup>3</sup>. This yielded a booting kernel at the first attempt. It turns
out, though, that you still need to ensure that <em>all</em> of the modules you are
going to need, <em>at any time in the future</em>, are loaded. I missed a couple.</p>

<p>Then I discovered this script by graysky,
<a href="https://github.com/graysky2/modprobed_db" title="In graysky2's github repo">modprobed_db</a>.
For a newbie to kernel compilation, this is simply invaluable. It allows you to
create a record of your used modules over time, compare it with those that are
currently loaded and then—right before you <code>make localmodconfig</code>—load the
remaining necessary ones. Foolproof kernel compilation. Just like that.
Brilliant. And, naturally enough, it is in
<a href="https://aur.archlinux.org/packages/modprobed_db/" title="AUR package">the AUR</a>.</p>

<p>Run the script, create your <span class="file">.conf</span> file and database in
<span class="file">$XDG_CONFIG_HOME/modprobed_db{,.conf}</span> and then either
call it from a <code>cron</code> job or, if you are impatient like me, spend a frenzied 10
minutes plugging ALL the devices you own into your machine, and you are good to
go. Running <code>sudo modprobed_db recall</code> will load all of the required modules,
you generate your kernel <span class="file">.config</span>, check it to make
sure it is complete and then run <code>make</code>.</p>

<p>On my laptop, I have 115 modules activated for a build, 10 of which need to be
recalled prior to creating the <span class="file">.config</span>. When I was
trying to debug 3.10.2, I compiled the vanilla Arch kernel using
<a href="https://wiki.archlinux.org/index.php/Abs" title="Wiki page on Arch Build System">ABS</a>
and it took almost exactly 60 minutes using all four threads on my i5. Building
my own kernel is done and installed in under 10.</p>

<p>I susbcribed to the <a href="https://www.kernel.org/feeds/kdist.xml" title="Kernel updates">RSS feed for kernel versions</a>
and now, whenever a new stable kernel is posted, I <code>wget</code> it, compile it and
boot from it. As new Arch versions appear in the repositories, they are updated
by <code>pacman</code> and happily coexist on my <span class="file">/boot</span>; thereby
ensuring that the likelihood of me being unable to boot my machine (other than
through
<acronym title="Problem Exists Between Keyboard And Chair">PEBKAC</acronym>)
has hopefully been staved off for another five years.</p>

<p>The next step would be to write a script that completely automates the process…</p>

<h3>Update 7/8/13</h3>

<p>After poring over PKGBUILDS in the AUR, principally graysky&#8217;s
<a href="https://aur.archlinux.org/packages/linux-ck/" title="Arch User Repository">linux-ck PKGBUILD</a>,
and the official
<a href="https://projects.archlinux.org/svntogit/packages.git/tree/trunk?h=packages/linux" title="Arch SVN Package Repo">ABS PKGBUILD</a>,
I decide to write my own to automate the above. It works well enough for me, but
hasn&#8217;t been tested more widely. You will need to ensure that you have an
up-to-date <code>modprobed_db</code> database with all of your required modules listed and
that you have configured <code>sudoers</code> to have this run from the PKGBUILD.</p>

<p>The PKGBUILD and the attendant files are in my
<a href="https://bitbucket.org/jasonwryan/shiv/src/tip/Build/linux-jwr" title="PKGBUILD and related files">bitbucket repo</a>:
let me know if there are any issues with this approach.</p>

<p><em>See also the follow up post on automating this process:</em> <a href="http://jasonwryan.com/blog/2013/08/24/automating-kernels/" title="Newer post">Automating Kernel Builds</a></p>

<h4>Notes</h4>

<ol>
<li>Other than those occassions for which I bear complete responsibility…</li>
<li>There are, of course, other benefits such as the self-satisfied glow of geek
accomplishment.</li>
<li>This is located in <span class="file">scripts/kconfig/</span>.</li>
</ol>


<p>Creative Commons image of kernels on Flickr by
<a href="http://www.flickr.com/photos/the_girl/56432091">Nadia Prigoda-Lee</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Encrypting Mutt]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/07/20/gnupg/"/>
    <updated>2013-07-20T09:36:00+12:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/07/20/gnupg</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/key-board.jpg" title="Encrypted mail" >
With the torrent of recent revelations about the enthusiasm with which
the governments of most of the first world have been systematically and
unlawfully violating the privacy of their citizens by intercepting their digital
communications, I thought it worth adding to the posts I have written about
<a href="http://jasonwryan.com/blog/categories/mutt/" title="Posts on mutt">Mutt</a>—that most
peerless of email clients—specifically how, combined with
<a href="http://gnupg.org/" title="GPG home page">GnuPG</a>, you can encrypt all of your mail and
ensure that the only person reading it is the intended recipient.</p>

<p>The definitive guide for this setup remains Justin Miller&#8217;s venerable page,
<a href="http://codesorcery.net/old/mutt/mutt-gnupg-howto" title="The title says it all, really…">Everything You Need To Know To Start Using GnuPG with Mutt</a>,
last edited in 2001 and <em>still</em> the authoritative source. The setup I will
describe differs only insofar as it covers how to use multiple keys associated
with different mail accounts. Mutt gives you the flexibility sign or encrypt all
of the email in your work account with one key, and your personal email with
another.</p>

<p>Once you have set up your GPG keys<sup>1</sup>, the first step is to configure
Mutt to use your keys. You can include these directives in your
<span class="file">muttrc</span> but, in the interests of readability, I prefer
to split them out into <span class="file">gpg.rc</span> and source them from
<span class="file">muttrc</span>. The settings are self-explanatory, those most
relevant to this post control how mutt handles your mail with respect to
encryption or just signing<sup>2</sup>:</p>

<figure class='code'> <div class="highlight"><pre><code class='sh'><span class='line'><span class="nb">set </span><span class="nv">pgp_use_gpg_agent</span> <span class="o">=</span> yes
</span><span class='line'><span class="nb">set </span><span class="nv">pgp_sign_as</span> <span class="o">=</span> 43A5CE95
</span><span class='line'><span class="nb">set </span><span class="nv">pgp_timeout</span> <span class="o">=</span> 3600
</span><span class='line'><span class="nb">set </span><span class="nv">crypt_autosign</span> <span class="o">=</span> yes
</span><span class='line'><span class="nb">set </span><span class="nv">crypt_replyencrypt</span> <span class="o">=</span> yes
</span></code></pre></div></figure>


<p>This sets my work key as the primary key and a couple of other sane (for me)
defaults. All of these options are described in <code>muttrc(5)</code>.
You can see my complete file in my
<a href="https://bitbucket.org/jasonwryan/shiv/src/default/.mutt/gpg.rc" title="mutt config files">bitbucket repo</a>.</p>

<p>The rest of the recipe is in <span class="file">muttrc</span>:</p>

<figure class='code'> <div class="highlight"><pre><code class='sh'><span class='line'><span class="nb">source</span> ~/.mutt/gpg.rc            <span class="c"># use GPG</span>
</span><span class='line'>
</span><span class='line'><span class="c"># gpg key</span>
</span><span class='line'>send-hook <span class="s2">&quot;~f @catalyst.net.nz&quot;</span>  <span class="nb">set </span><span class="nv">pgp_sign_as</span><span class="o">=</span>43A5CE95
</span><span class='line'>send-hook <span class="s2">&quot;~f @jasonwryan.com&quot;</span>   <span class="nb">set </span><span class="nv">pgp_sign_as</span><span class="o">=</span>B1BD4E40
</span><span class='line'>
</span><span class='line'><span class="c"># key binds</span>
</span><span class='line'><span class="nb">bind </span>compose p  pgp-menu
</span><span class='line'>macro compose Y pfy <span class="s2">&quot;send mail without GPG&quot;</span>
</span></code></pre></div></figure>


<p>Sourcing the <span class="file">gpg.rc</span> reads all the relevant options
and then a series of <code>send-hooks</code> allow you to use specific keys for each of
your accounts.</p>

<p>Now, when you receive encrypted mail, if your key agent is running, Mutt will
decrypt your mail on the fly. Otherwise you will be prompted for your key
phrase. Similarly, when you send email, it will by default be signed by the key
associated with that account, and you can encrypt individual mail by bringing up
the GPG menu in the compose screen by hitting <kbd>p</kbd>.</p>

<p>And for those friends and acquaintances you correspond with for whom
encryption is the equivalent of white powder spilling from an envelope, you can
always elect to send without any GPG by selecting <kbd>Y</kbd> to send the
email.</p>

<p>These and a number of other interesting tips and macros are on the
<a href="http://dev.mutt.org/trac/wiki/MuttGuide/UseGPG" title="Using GPG">Mutt Wiki</a>
and are worth following up once you have the basics working. Like so much of
this sort of software, it takes a little longer to set up <em>exactly</em> the way that
you want it, but once you are done, it is good for decades…</p>

<h4>Notes</h4>

<ol>
<li>A good introduction to this procedure is detailed in the
<a href="https://wiki.archlinux.org/index.php/GPG">Arch Wiki article</a>.</li>
<li>This assumes that you do want to distinguish between the two; you could, of
course, just encrypt <em>everything</em>—assuming that your correspondents were
willing and able to decrypt it…</li>
</ol>


<p>Creative Commons image by <a href="http://www.flickr.com/photos/54450095@N05/8229504229/">Intel Free Press</a> on Flickr.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RPi Headless Torrent Box]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/06/29/raspberry/"/>
    <updated>2013-06-29T09:40:00+12:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/06/29/raspberry</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/raspberry-pi-logo.png" title="Raspberry Pi logo" >
I was fortunate enough to be given a
<a href="http://www.raspberrypi.org/" title="Pi homepage">Raspberry Pi</a> earlier this year
and, naturally enough, have been running
<a href="http://archlinuxarm.org/" title="Arch Linux ARM site">Arch ARM</a> on it over the
last several months. Initially, I was at somewhat of a loss as to what to do
with it, so was just (under)using it<sup>1</sup> for a persistent IRC connection.
I have now, with very little effort, set it up as a headless torrent box and it is
working nicely.</p>

<p>As is generally the case, this involved little more than stitching together a
few lightweight tools to accomplish the task. In this case, it is a combination
of
<a href="http://libtorrent.rakshasa.no/" title="rotrrent homepage">rtorrent</a>
(with the canvas-colour patch applied),
<a href="http://jasonwryan.com/blog/categories/surfraw/" title="Posts on surfraw">surfraw</a>
and
<a href="http://w3m.sourceforge.net/" title="w3m homepage">w3m</a> for discovering
torrents,<sup>2</sup>
<a href="http://labs.bittorrent.com/experiments/sync.html" title="Peer to Peer synching">bittorrent sync</a>
and, optionally, a <acronym title="Virtual Private Network">VPN</acronym>.</p>

<p>I use a 16GB <acronym title="Universal Serial Bus">USB</acronym> drive to act as
storage for the device, and mount it at <span class="file">~/Downloads</span>
via <span class="file">/etc/fstab</span>; depending on the size of your
<acronym title="Secure Digital">SD card</acronym>, this may be superfluous.</p>

<p>First a note on building packages; building <em>anything</em> on the Pi—with only
512MB <acronym title="Random Access Memory">RAM</acronym>—is a protracted
and thankless task. So if you intend to do more of this, or do it regularly,
set up
<a href="http://archlinuxarm.org/developers/distcc-cross-compiling" title="Arch ARM instructions">cross-compiling</a>;
you won&#8217;t regret the initial investment.</p>

<p><code>rtorrent</code> is in the ARM repos, but I wanted to patch in colour, so I wrote
<a href="https://gist.github.com/jasonwryan/5794623" title="Gist of the thing…">a PKGBUILD</a>,
based on the package in [community] and
<a href="https://aur.archlinux.org/packages.php?ID=31956" title="Arch User Repository">ashren&#8217;s AUR package</a>.
Once you have rtorrent installed and working, the rest is straightforward.</p>

<p>The default config for w3m is perfectly functional, but can be easily customized
further. The key to this setup is being able to find a torrent and then easily
add it to rtorrent&#8217;s queue.  To do this, I modified the hack that I wrote up
<a href="http://jasonwryan.com/blog/2011/05/05/w3m/" title="Post on yanking URLs in w3m">a couple years back</a>.
Essentially, you use w3m&#8217;s external link function to trigger a script to grab
the magnet link. Like so:</p>

<figure class='code'><figcaption><span>~/.w3m/config </span></figcaption>
 <div class="highlight"><pre><code class='sh'><span class='line'>extbrowser /home/jason/Scripts/magnets %s
</span></code></pre></div></figure>


<p>and the script from the
<a href="http://wiki.rtorrent.org/MagnetUri#Handling_.22magnet:.22_URIs_via_a_bash_script" title="Script for magnet links">rtorrent wiki</a>:</p>

<figure class='code'><figcaption><span>~/Scripts/magnets </span></figcaption>
 <div class="highlight"><pre><code class='sh'><span class='line'><span class="c">#!/bin/bash</span>
</span><span class='line'><span class="nb">cd</span> <span class="nv">$HOME</span>/Downloads/Queue/watch/    <span class="c"># set your watch directory here</span>
</span><span class='line'><span class="o">[[</span> <span class="s2">&quot;$1&quot;</span> <span class="o">=</span>~ <span class="nv">xt</span><span class="o">=</span>urn:btih:<span class="o">([</span>^&amp;/<span class="o">]</span>+<span class="o">)</span> <span class="o">]]</span> <span class="o">||</span> <span class="nb">exit</span>;
</span><span class='line'><span class="nb">echo</span> <span class="s2">&quot;d10:magnet-uri${#1}:${1}e&quot;</span> &gt; <span class="s2">&quot;meta-${BASH_REMATCH[1]}.torrent&quot;</span>
</span></code></pre></div></figure>


<p>Remapping the w3m key to trigger the script to make it more Vim-like:</p>

<figure class='code'><figcaption><span>~/.w3m/keymap </span></figcaption>
 <div class="highlight"><pre><code class='sh'><span class='line'>keymap Y EXTERN_LINK
</span></code></pre></div></figure>


<p>And now hitting <kbd>Shift</kbd><kbd>y</kbd> over a magnet link adds it to your
queue.</p>

<p>The final piece was to ameliorate the step of transferring the completed files
from the Pi, or for allowing me to add torrents remotely. To do this, I used
a <a href="http://jasonwryan.com/blog/2013/03/16/sync/" title="My post on Sync">bittorrent sync</a>
shared directory as <span class="file">~/Downloads</span>. All files are synched
to my desktop as they are downloaded to the Pi. Simple.</p>

<p><img src="http://miromiro.com/Blog-images/rtorrent-2.png" title="'Screenshot of rtorrent in action…'" ></p>

<p>As I mentioned above, you could also use a VPN and, with a service
file, have it connect on boot if you wished to further protect your privacy.</p>

<h4>Notes</h4>

<ol>
<li>This is not to say that I am now using it to it&#8217;s full potential; quite the
opposite. Recommendations or suggestions gratefully received.</li>
<li>Discovery is <em>your</em> business; what you choose to download and share may be the
business of copyright holders…</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Asking for Help]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/06/15/asking/"/>
    <updated>2013-06-15T10:39:00+12:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/06/15/asking</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/bowl.jpg" title="'Flickr image of Begging Bowl'" >
Another great peristaltic movement in Arch&#8217;s rolling release digestive system
happened over the last couple of weeks, the move of all binaries
<a href="https://www.archlinux.org/news/binaries-move-to-usrbin-requiring-update-intervention/" title="Arch News update">to /usr/bin</a>.
This move had been foreshadowed for several months and, despite announcements
on the front page of the Arch website, the mailing lists and the release going
through [testing] and the resulting thread on the forums, there was still a
surprising amount of carnage<sup>1</sup> in it&#8217;s wake.</p>

<p>In the aftermath (although I expect that it will take some months for it to
completely pass through the system), what struck me was not so much the variety
and ingenuity of the ways people had managed to break their installs<sup>2</sup>
as how they approached the community seeking help afterwards.</p>

<p>There are already some fine guides on how to do this, notably
ESR&#8217;s <a href="http://www.catb.org/esr/faqs/smart-questions.html" title="Just read it…">How to ask Questions the Smart Way</a>
and—specifically for Arch—zendeavour&#8217;s
<a href="http://redd.it/tjjwr" title="On Reddit">troubleshooting for newcomers</a>;
this isn&#8217;t an attempt to add or expand on that genre. Rather, it is
a look at a subset of attitudes that some people adopt<sup>3</sup>
as they seek the assistance of the community.</p>

<p>The first is the <strong>blamer</strong>. The proponent of the  “all-guns-blazing” approach.
I&#8217;ll paraphrase, but there are enough examples on the boards to illustrate the
point: “my system can&#8217;t boot, it&#8217;s not my fault and I am here to let you know
that I am unhappy and demand recourse.” This is, unquestionably, the most
puzzling of all the strategies. It is often coupled with the (sadly almost
always empty) threat to abandon the distro and it&#8217;s apparently beleaguered
community.</p>

<p>Puzzling because I have yet to encounter a single situation in life, online
or off, where opening with hostility and blame is an intelligent approach to
seeking assistance. If you are going to adopt this approach, please supersize
to “rage quit” and expend your energy actually delivering on your threat.</p>

<p>The next is the <strong>wheedler</strong>. Less objectionable than the incendiary approach,
it is nonetheless similarly ineffective. Wheedlers are distinguished by
peppering their posts liberally with declarations of their ineptitude and
“noobness”, in the mistaken belief that this will engender a wave of sympathy
prior to soothing hand-holding and spoon-feeding. There is a strong correlation
between this behaviour and the various types of
<a href="http://jasonwryan.com/blog/2012/03/17/vampires/" title="Post on the taxonomy of vampires">help vampirism</a>.</p>

<p>Wheedling won&#8217;t lead to quicker, or more informed, advice and assistance; in
all likelihood it will just discourage others from helping because
they can see that rewarding this sort of behaviour has a longer-term
deleterious impact on the health of the community.</p>

<p>Then there is the <strong>Vulcan</strong>. A curiosity more than an annoyance, these
people seem to inhabit some sort of adolescent fantasy land where the Internet
is a venue for them to revel in their almost superhero-like powers of technical
<em>awesomeness</em>; said powers manifesting to others as a sort of benign
cluelessness.</p>

<p>Their posts are invariably brief and completely devoid of relevant detail to the
point of cryptic because, “hey, we all <em>know</em> what this issue is,” and are
littered with smilies and that stupid emoticon with the sunglasses. Rather than
actually describing their problem, they want people to think that, by a process
of <a href="http://en.memory-alpha.org/wiki/Vulcan_mind_meld" title="There is a Star Trek wiki?">mind-melding</a>,
other “hackers” will intuit the subtle depth and intricacy of the issue and
then type out a detailed step-by-step guide of how to solve it.</p>

<p>Finally, there is the <strong>conspiracist</strong>. These malcontents see every
significant change in Arch as being part of a wider agenda to corrupt the purity
of the UNIX® philosophy. They also tend to blame
<a href="https://en.wikipedia.org/wiki/Lennart_Poettering" title="Lennarts wikipedia page">Lennart Poettering</a>
for <em>everything</em>. These unfortunates are clearly already suffering such mental anguish
trying to reconcile their obsessiveness about the past with a rolling
release that they deserve our pity more than our contempt (but I am equally
happy providing either)…</p>

<p>As I said, these are fortunately just a subset and very much represent the
minority of attitudes.  The vast majority tend to be aware that, at
one time or another, <em>everyone</em> will need some help to solve a problem.
Therefore it is best to approach it in a matter-of-fact way, using the practical
guidance on asking questions on a technical forum, and with a degree of humility
and a willingness to learn from the people who are prepared to share their
knowledge and experience.</p>

<h4>Notes</h4>

<ol>
<li>Where “carnage” should be understood as a minor PEBKAC epidemia…</li>
<li>From shutting down mid-update (because a reboot fixes <em>everything</em>) to
still using <code>consolekit</code>, <code>initscripts</code> and <code>grub-legacy</code>: all deprecated some time
ago.</li>
<li>I resisted linking to specific posts on the boards to provide actual examples,
the more motivated among you will find them without difficulty.</li>
</ol>


<p>Flickr Creative Commons image by
<a href="http://www.flickr.com/photos/buddhist_fox/4795942625/">Buddhist Fox</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Replacing Google Reader]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/05/25/greader/"/>
    <updated>2013-05-25T09:10:00+12:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/05/25/greader</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/commafeed.png" title="'CommaFeed Logo'" >
I have been using <a href="https://en.wikipedia.org/wiki/Google_reader" title="Wikipedi page">Google Reader</a>
everyday since I first discovered the service over seven years ago. It is my
primary source of news and information and the announcement that Google is, on July 1 this year,
set to <a href="http://googlereader.blogspot.ca/2013/03/powering-down-google-reader.html" title="Official announcemet on Google Blog">shut down Reader</a>
was something considerably more than just an inconvenience for me.</p>

<p>Over the years, I had looked at other <acronym title="Rich Site Summary">RSS</acronym>
readers but, for a variety of reasons, had invariably found that the speed,
simplicity and flexibility that Google Reader offered meant that any dalliances
were unsatisfactory and short-lived. I resigned myself to having to settle for
an inferior alternative, rather than moving to a genuine replacement.</p>

<p>On the recommendation of <a href="https://pinboard.in/" title="Not so-social bookmarking">@pinboard</a>,
I first signed up for a premium account at
<a href="https://www.newsblur.com/" title="NewsBlur website">NewsBlur</a>. It is open source and,
given the recommendation from Maciej<sup>1</sup>, I was hopeful that it would
bridge the gap. Newsblur is a good service (especially considering the rush of
signups in the days after the Google announcement), but it has a couple of
critical weaknesses for me: no search (yes, you read that correctly—there is <em>no
way to search through your feeds</em>) and, less importantly but just as annoying,
occasionally sluggish performance.</p>

<p>After a couple of weeks using NewBlur I happily stumbled across
<a href="https://www.commafeed.com/" title="CommaFeed homepage">CommaFeed</a>, a
Reader clone that emulates the austere minimalism of Google Reader. Apart from
the fact that it is open source, the other aspect that attracted me to it
was the ability to run it on Red Hat&#8217;s Platform as a Service offering,
<a href="http://www.openshift.com/" title="Red Hat PaaS">OpenShift</a>.</p>

<p>The README on the <a href="https://github.com/Athou/commafeed" title="CommaFeed repo">Github repo</a>
explains how to set it all up. Unfortunately, due to an
<a href="https://github.com/Athou/commafeed/issues/91" title="OpenShift fails silently">open issue</a>,
some manual intervention is required, but it is still a very
straightforward and painless process to get your own instance of CommaFeed up
and running.</p>

<p>Creat an OpenShift account, log in and add the JBoss 6.0 application (or
cartridge as it is called on OpenShift) and the MySQL cartridge. Once your setup
is created, add your public <acronym title="Secure Shell">SSH</acronym> key and,
under your <code>My Applications</code> tab, copy down your Git repo address, which will be
of the form:</p>

<figure class='code'> <div class="highlight"><pre><code class='sh'><span class='line'>ssh://76758382475ef809976543@<span class="nv">$appname</span>-<span class="nv">$namespace</span>.rhcloud.com/~/git/feeds.git/
</span></code></pre></div></figure>


<p>Then you need to make a local clone of CommaFeed and push it to the Red Hat
server:</p>

<figure class='code'> <div class="highlight"><pre><code class='sh'><span class='line'>git clone https://github.com/Athou/commafeed.git
</span><span class='line'><span class="nb">cd </span>commafeed
</span><span class='line'><span class="c"># add OpenShift as a repo</span>
</span><span class='line'>git remote add openshift -f ssh://76758382475ef809976543@<span class="nv">$appname</span>-<span class="nv">$namespace</span>.etc…
</span><span class='line'>git merge openshift/master -s recursive -X ours
</span><span class='line'>git push openshift master
</span></code></pre></div></figure>


<p>This will then trigger a series of hooks that build the application and restart
the server. If everything goes well you will see something like:</p>

<figure class='code'> <div class="highlight"><pre><code class='sh'><span class='line'>remote: <span class="o">[</span>INFO<span class="o">]</span> ------------------------------------------------------------------------
</span><span class='line'>remote: <span class="o">[</span>INFO<span class="o">]</span> BUILD SUCCESS
</span><span class='line'>remote: <span class="o">[</span>INFO<span class="o">]</span> ------------------------------------------------------------------------
</span><span class='line'>remote: <span class="o">[</span>INFO<span class="o">]</span> Total <span class="nb">time</span>: 3:18.195s
</span><span class='line'>remote: <span class="o">[</span>INFO<span class="o">]</span> Finished at: Mon May 20 03:21:37 EDT 2013
</span><span class='line'>remote: <span class="o">[</span>INFO<span class="o">]</span> Final Memory: 42M/185M
</span><span class='line'>remote: <span class="o">[</span>INFO<span class="o">]</span> ------------------------------------------------------------------------
</span><span class='line'>remote: Running .openshift/action_hooks/build
</span><span class='line'>remote: Running .openshift/action_hooks/deploy
</span><span class='line'>remote: <span class="nv">hot_deploy_added</span><span class="o">=</span><span class="nb">false</span>
</span><span class='line'>remote: MySQL already running
</span><span class='line'>remote: Found 127.12.712.712:8080 listening port
</span><span class='line'>remote: Done
</span><span class='line'>remote: Running .openshift/action_hooks/post_deploy
</span><span class='line'>To ssh://76758382475ef809976543@<span class="nv">$appname</span>-<span class="nv">$namespace</span>.rhcloud.com/~/git/feeds.git/
</span></code></pre></div></figure>


<p>You now have CommaFeed successfully running on OpenShift. After a couple of
minutes, visit the public <acronym title="Unique Resource Locator">URL</acronym>
and you will be able to login to your CommaFeed instance. Updating your
CommaFeed is as simple as pulling to your local repo, merging and
then pushing to <code>openshift master</code>.</p>

<p>Importing directly from Google Reader still seems broken (I was  getting
errors from builds late this week), but if you import from an existing <code>.opml</code>
or <code>.xml</code> file you will see CommaFeed in all it&#8217;s glory:</p>

<p><img class="left" src="http://miromiro.com/Blog-images/commafeed_screen.png" title="'ComaFeed screenshot'" ></p>

<p>As you can see, it is remarkably similar to the Google Reader interface; a
clean, minimalist design that is focussed—quite rightly—on the content. There
is an option to load your own <code>.css</code> if you want to apply some additional
styling, but for me the base style is just about perfect.</p>

<p>More impressively, in the week or so that I have been using CommaFeed, the
developer,
<a href="https://github.com/Athou" title="Athou on Github">Athou</a>, has been committing
enhancements and bug fixes several times <em>a day</em>; almost every night,
I have pushed changes to OpenShift, reloaded my browser and found a
smoother, enhanced feed reader with additional functionality; it is
literally growing in leaps and bounds, and is a great reminder of the power
of open source<sup>2</sup>.</p>

<p>The performance of OpenShift has also been solid; feeds are delivered
seemingly instantaneously and, apart from the slight lag after restarting
the application, I haven&#8217;t experienced any issues whatsoever in terms
of availability.</p>

<p>There are still a couple of areas where CommaFeed can be improved. Most
notably, there is an open feature request for a
<a href="https://github.com/Athou/commafeed/issues/54" title="Github Issue">mobile friendly CSS</a>
and this is badly needed, the site is pretty much unusable on my phone. With
any luck, some enterprising Android developer will build a CommaFeed app (for
which I would happily pay good money)…</p>

<p>In any event, if you are looking for a Google Reader replacement, try
running CommaFeed (either on your own server or one of Red Hat&#8217;s); for
a project that is only a couple of months old, it has covered a
tremendous amount of ground and will undoubtedly continue to grow
and improve.</p>

<h4>Notes</h4>

<ol>
<li>In conjunction with his great advice about not being a
<a href="http://blog.pinboard.in/2011/12/don_t_be_a_free_user/" title="Pinboard blog">free user</a>.</li>
<li>The <a href="http://feeds-jwr.rhcloud.com/#/feeds/help" title="About and Help page">about page</a>
has a donate button: if you want to support an application which I have no doubt
will soon be even better than Google Reader, you might want to use it.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hacking PKGBUILDs]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/05/18/pkgbuilds/"/>
    <updated>2013-05-18T10:10:00+12:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/05/18/pkgbuilds</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/woodcutting.jpg" title="'Cutting wood'" >
I posted a couple of weeks ago about
<a href="http://jasonwryan.com/blog/2013/03/29/vim/" title="Post on Vim">Building Vim</a> and how,
using <a href="https://wiki.archlinux.org/index.php/Abs" title="Arch Build System on the Wiki">ABS</a>
and <code>makepkg</code> it is possible to customize packages in the repositories to suit your
individual requirements, in that case with a specific feature set.</p>

<p>One of Arch&#8217;s real strengths is in the flexibility that <code>makepkg</code> and PKGBUILDs provide
the community; the ability to adapt official packages—or unofficial ones in the
<a href="https://aur.archlinux.org/" title="Arch User Repository">AUR</a>—as you see fit. As PKGBUILDs
are just shell scripts, the entry level to start playing around with them is quite
low<sup>1</sup>.</p>

<p>A fairly standard, and simple, example of the type of customization that I might make
is with <a href="http://tools.suckless.org/dmenu/" title="dmenu page">dmenu</a>, the suckless dynamic
menu, where the
<a href="https://www.archlinux.org/packages/community/x86_64/dmenu/" title="Arch package">standard package</a>
in the Arch repositories is not patched for Xft support. There is a patch for this on the
<a href="http://tools.suckless.org/dmenu/patches/xft" title="Xft patch on suckless.org">suckless wiki</a>, so it
is just a case of making the requisite changes in the PKGBUILD from ABS and building it.</p>

<p>As you can see from the <code>diff</code> below, there is not a lot involved in this exercize; essentially,
adding <code>libxft</code> as a dependency, sourcing the patch from the suckless site (and including the
hash for it), and then in the <code>build</code> function ensuring that the patch is applied and the
Makefile updated with the new library:</p>

<figure class='code'> <div class="highlight"><pre><code class='diff'><span class='line'><span class="gd">--- PKGBUILD   2013-05-18 09:33:07.156328812 +1200</span>
</span><span class='line'><span class="gi">+++ PKGBUILD   2012-11-14 09:25:15.915335588 +1300</span>
</span><span class='line'><span class="gu">@@ -11,16 +6,22 @@</span>
</span><span class='line'> pkgdesc=&quot;A generic menu for X&quot;
</span><span class='line'> url=&quot;http://tools.suckless.org/dmenu/&quot;
</span><span class='line'> arch=(&#39;i686&#39; &#39;x86_64&#39;)
</span><span class='line'><span class="gi">+groups=(&#39;modified&#39;)</span>
</span><span class='line'> license=(&#39;MIT&#39;)
</span><span class='line'><span class="gd">-depends=(&#39;sh&#39; &#39;libxinerama&#39;)</span>
</span><span class='line'><span class="gd">-source=(http://dl.suckless.org/tools/$pkgname-$pkgver.tar.gz)</span>
</span><span class='line'><span class="gd">-md5sums=(&#39;9c46169ed703732ec52ed946c27d84b4&#39;)</span>
</span><span class='line'><span class="gi">+depends=(&#39;sh&#39; &#39;libxinerama&#39; &#39;libxft&#39;)</span>
</span><span class='line'><span class="gi">+source=(http://dl.suckless.org/tools/$pkgname-$pkgver.tar.gz</span>
</span><span class='line'><span class="gi">+http://tools.suckless.org/dmenu/patches/$pkgname-$pkgver-xft.diff)</span>
</span><span class='line'><span class="gi">+md5sums=(&#39;9c46169ed703732ec52ed946c27d84b4&#39;</span>
</span><span class='line'><span class="gi">+         &#39;d448ec9120718b0aedbdb338f4fa69ba&#39;)</span>
</span><span class='line'>
</span><span class='line'> build(){
</span><span class='line'>   cd $srcdir/$pkgname-$pkgver
</span><span class='line'><span class="gi">+  patch -p1 &lt; ../$pkgname-$pkgver-xft.diff</span>
</span><span class='line'><span class="gi">+  sed -i &#39;s:-I/usr/local/include/freetype2:-I/usr/include/freetype2:&#39; config.mk</span>
</span><span class='line'><span class="gi">+</span>
</span><span class='line'>   make \
</span></code></pre></div></figure>


<p>Running <code>makepkg -i</code> will build and install dmenu with Xft support. This is the most
straightforward approach. I also, primarily by way of experimentation and in an effort
to try an understand how this actually works, have slightly more convoluted examples.
<a href="https://www.archlinux.org/packages/extra/x86_64/msmtp/" title="Arch package">msmtp</a>, the
<acronym title="Simple Mail Transfer Protocol">SMTP</acronym> client has a couple
of makedepends in
<a href="https://www.archlinux.org/packages/extra/x86_64/libgnome-keyring/" title="Arch package">libgnome-keyring</a>
and <a href="https://www.archlinux.org/packages/extra/any/texlive-core/" title="Arch package">texlive-core</a>; the former
I have zero use for and the latter is only installed on my desktop, so I have no wish to install it on
my laptop just to be able to send emails…</p>

<p>In this case, I modified the PKGBUILD to completely remove the <code>libgnome-keyring</code> dependency
and to only build the <code>msmtp</code> documentation in <code>.pdf</code> and <code>.html</code> if <code>texlive-core</code> was
already installed on the machine. Unfortunately, I wasn&#8217;t able to test for the presence of
<code>texlive-core</code> with the standard utilities like <code>type</code> or <code>which</code>, so—as it is installed
on all my boxes—I went with <code>expac</code> (<code>pacman -Q</code> would also work):</p>

<figure class='code'> <div class="highlight"><pre><code class='diff'><span class='line'><span class="gd">--- PKGBUILD    2013-05-18 09:32:07.393095131 +1200</span>
</span><span class='line'><span class="gi">+++ PKGBUILD    2013-05-18 09:31:55.449986364 +1200</span>
</span><span class='line'><span class="gu">@@ -1,7 +1,8 @@</span>
</span><span class='line'> arch=(&#39;i686&#39; &#39;x86_64&#39;)
</span><span class='line'><span class="gi">+groups=(&#39;modified&#39;)</span>
</span><span class='line'> license=(&#39;GPL3&#39;)
</span><span class='line'> url=&quot;http://msmtp.sourceforge.net&quot;
</span><span class='line'><span class="gd">-makedepends=(&#39;texlive-core&#39; &#39;gsasl&#39; &#39;libgnome-keyring&#39;)</span>
</span><span class='line'><span class="gi">+makedepends=(&#39;gsasl&#39;)</span>
</span><span class='line'> source=(http://download.sourceforge.net/sourceforge/msmtp/${pkgbase}-${pkgver}.tar.bz2)
</span><span class='line'> sha1sums=(&#39;c0edce1e1951968853f15209c8509699ff9e9ab5&#39;)
</span><span class='line'>
</span><span class='line'><span class="gu">@@ -12,19 +13,24 @@</span>
</span><span class='line'>
</span><span class='line'> build() {
</span><span class='line'>   cd ${pkgbase}-${pkgver}
</span><span class='line'><span class="gd">-  ./configure --prefix=/usr --sysconfdir=/etc --with-ssl=gnutls</span>
</span><span class='line'><span class="gi">+  ./configure --prefix=/usr --sysconfdir=/etc --with-ssl=gnutls --without-gnome-keyring</span>
</span><span class='line'>   make
</span><span class='line'><span class="gd">-  make -C doc html pdf</span>
</span><span class='line'><span class="gi">+  if [[ -n $(expac -Q &#39;%n&#39; texlive-core) ]]; then</span>
</span><span class='line'><span class="gi">+      make -C doc html pdf</span>
</span><span class='line'><span class="gi">+  fi</span>
</span><span class='line'> }
</span><span class='line'>
</span><span class='line'> package_msmtp() {
</span><span class='line'>   pkgdesc=&quot;A mini smtp client&quot;
</span><span class='line'><span class="gd">-  depends=(&#39;gsasl&#39; &#39;libgnome-keyring&#39;)</span>
</span><span class='line'><span class="gi">+  depends=(&#39;gsasl&#39;)</span>
</span><span class='line'>   install=msmtp.install
</span><span class='line'>
</span><span class='line'>   cd ${pkgbase}-${pkgver}
</span><span class='line'>   make DESTDIR=&quot;${pkgdir}&quot; install
</span><span class='line'><span class="gi">+</span>
</span><span class='line'><span class="gi">+  if [[ -n $(expac -Q &#39;%n&#39; texlive-core) ]]; then</span>
</span><span class='line'>   make DESTDIR=&quot;${pkgdir}&quot; -C doc install-html install-pdf
</span><span class='line'><span class="gi">+  fi</span>
</span><span class='line'>
</span><span class='line'> # Installing example configs and scripts to /usr/share/doc/msmtp
</span></code></pre></div></figure>


<p>It isn&#8217;t necessarily an attractive solution, but it works for me…
On the subject of unattractive solutions, as of pacman 4.1, released
last month, the packaging standards for
<a href="https://wiki.archlinux.org/index.php/VCS_PKGBUILD_Guidelines" title="Arch Wiki page">VCS PKGBUILDs</a>
have been changed, principally around how sources and versioning is handled. For
the couple of VCS packages I maintain in the <acronym title="Arch User
Repository">AUR</acronym><sup>2</sup>, I have been
experimenting with how to capture the <code>pkgver</code> in a way that conforms to the
standards and provides people with a meaningful version number.</p>

<p>By default, the version number for these projects from their git repos
is not that helpful:</p>

<figure class='code'> <div class="highlight"><pre><code class='sh'><span class='line'>git describe --always
</span><span class='line'>4861046
</span></code></pre></div></figure>


<p>After looking through the git logs, and playing around with <code>awk</code> to filter
the results, I came up with this:</p>

<figure class='code'> <div class="highlight"><pre><code class='sh'><span class='line'>pkgver<span class="o">()</span> <span class="o">{</span>
</span><span class='line'>  <span class="nb">cd</span> <span class="s2">&quot;$_gitname&quot;</span>
</span><span class='line'>  <span class="nb">printf</span> <span class="s1">&#39;%s\n&#39;</span> <span class="s2">&quot;$(awk &#39;/^ / {print $2}&#39; &lt;(git log --grep=version -1))_\</span>
</span><span class='line'><span class="s2">  $(git describe --always)&quot;</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></div></figure>


<p>This prints a more, for me anyway, intelligble package version: <code>vimprobable2-git
1.2.1_c5936cc-1</code> that relates back to the last stable release and appends the
current commit. I&#8217;m sure that this could be improved upon; suggestions are
welcome.</p>

<p>The other change to note in all of these PKGBUILDs is the inclusion of the
<code>groups</code> variable. By adding all of the modified packages from the official
repositories to the—imaginatively titled—<code>modified</code> group, I can then add a line
to <code>/etc/pacman.conf</code> that prevents those packages from being overwritten on
upgrade<sup>3</sup>:</p>

<figure class='code'> <div class="highlight"><pre><code class='sh'><span class='line'><span class="nv">IgnoreGroup</span> <span class="o">=</span> modified
</span></code></pre></div></figure>


<p>Issuing <code>pacman -Syu</code>, or running <code>checkupdates</code> from a <code>cron</code> job, will
notify you that the packages have had a version bump and that they need
to be rebuilt. The PKGBUILDs for all of these packages can be found in
<a href="https://bitbucket.org/jasonwryan/centurion/src/ff3b3c9d805e197f35aa28dbeb6a9a6555ee7b63/Build?at=default" title="Files in bitbucket">my bitbucket repo</a>.</p>

<h4>Notes</h4>

<ol>
<li>As my experiments attest…</li>
<li><a href="https://aur.archlinux.org/packages/vimprobable2-git/">Vimprobable2-git</a>,
<a href="https://aur.archlinux.org/packages/surfraw-git/">Surfraw-git</a> and
<a href="https://aur.archlinux.org/packages/ruby-build-git/">ruby-build-git</a>.</li>
<li>All credit to ataraxia <a href="https://bbs.archlinux.org/viewtopic.php?pid=623841#p623841">for this idea</a>.</li>
</ol>


<p>Creative Commons image on Flickr by
<a href="http://www.flickr.com/photos/wellspwilson/6481217091/" title="Wood
Cutting Wood">Wells P. Wilson</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AUR Helpers]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/04/09/helpers/"/>
    <updated>2013-04-09T19:07:00+12:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/04/09/helpers</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/crutches.jpg" title="'Crutches on Flickr'" ></p>

<h3>Or, &#8220;Why you should uninstall Yaourt and embrace <em>makepkg</em>…&#8221;</h3>

<p>The <a href="https://bbs.archlinux.org/viewtopic.php?id=160655" title="Announcement on the Arch boards">release of Pacman 4.1</a>
saw the same flurry of posts on the boards, in IRC and the mailing lists about
people being “unable” to upgrade or, worse, claiming that pacman was “broken”
because their upgrade was failing due to unsatisfied dependencies, that pretty
much every pacman upgrade ocassions. How is it possible that so many people can
run an operating system designed for competent users without having even a
basic understanding of how the package manager—one of the single most critical
components of the distribution—works?</p>

<p>Even a cursory perusal of the resulting threads on the boards will quickly
identify the common denominator in these cases:</p>

<blockquote><p>resolving dependencies&#8230;<br/>looking for inter-conflicts&#8230;<br/>error: failed to prepare transaction (could not satisfy dependencies)<br/>:: package-query: requires pacman<4.1</p></blockquote>


<p><a href="https://aur.archlinux.org/packages/package-query/" title="AUR page">package-query</a>
is required by <a href="https://aur.archlinux.org/packages/yaourt/" title="yaourt on AUR">yaourt</a>;
so these upgrades have been stymied by a package that is in the (unsupported)
<acronym title="Arch User Repository">AUR</acronym>? There are a
<a href="https://wiki.archlinux.org/index.php/AUR_Helpers" title="Arch Wiki entry">multitude of AUR helpers</a>,
but <code>yaourt</code> is most commonly used by people who are new to Arch<sup>1</sup>
for two reasons.  First, it is one of the most “featureful” and secondly, and
more to the point of my argument, it can be installed by simply adding an
unsupported repo to <code>pacman.conf</code>; thereby effectively bypassing the need for
the hapless user ever having to use or understand <code>makepkg</code>.</p>

<p>Consequently, over time, people who are habitually using <code>yaourt -Syu --aur</code> to
update both the packages in the supported repositories and those they have
installed from the AUR lose the conceptual distinction between the two.
<code>yaourt</code> obscures this from them and—if they are completely reliant upon it, as
these threads attest they are—they have abnegated responsibility for managing
those unsupported packages and in doing so have found themselves incapable of
understanding the bind they are in.</p>

<p>This sort of obscuring of fundamental operating principles in the pursuit of
“convenience” is anathema to Arch and is precisely the reason I moved away from
using <code>yaourt</code> (and indeed from using Ubuntu when I jumped from that sinking
ship). Any convenience is purely illusory, in reality it just fosters
<a href="http://en.wikipedia.org/wiki/Learned_helplessness" title="Wikipedia entry">learned helplessness</a>.</p>

<p>I understand that the <code>yaourt</code> developer(s) was scratching their own itch, and
this post is not about maligning the project; but there are significant
unintended consequences of giving people a tool that abstracts such a
fundamental element of the distribution away from the user, especially for a
distribution where you are expected to have
<a href="https://wiki.archlinux.org/index.php/The_Arch_Way#User-centric" title="The Arch Way">complete control <em>and responsbility</em> over your system</a>.</p>

<p>To be clear, I don&#8217;t have a complaint with the <em>concept</em> of AUR helpers. I used
<code>yaourt</code> initially before switching to
<a href="http://pbrisbin.com/posts/aurget" title="Patrick Brisbin's AUR helper">aurget</a> and then
alighting on
<a href="https://github.com/falconindy/cower" title="Cower on github">cower</a>, or more particularly,
a partial wrapper for <code>cower</code>:</p>

<figure class='code'><figcaption><span>cowerd </span></figcaption>
 <div class="highlight"><pre><code class='sh'><span class='line'><span class="c">#!/bin/sh</span>
</span><span class='line'><span class="c"># install AUR packages with cower</span>
</span><span class='line'>
</span><span class='line'><span class="nb">cd</span> <span class="nv">$HOME</span>/Build <span class="o">&amp;&amp;</span> cower -d <span class="s2">&quot;$1&quot;</span>
</span><span class='line'><span class="nv">builddir</span><span class="o">=</span><span class="s2">&quot;$_&quot;</span>
</span><span class='line'><span class="nb">cd</span> <span class="s2">&quot;$builddir&quot;</span> <span class="o">&amp;&amp;</span> <span class="k">${</span><span class="nv">EDITOR</span><span class="k">:-</span><span class="nv">vi</span><span class="k">}</span> PKGBUILD
</span><span class='line'>
</span><span class='line'>makepkg -si <span class="o">&amp;&amp;</span> <span class="nb">cd</span> - &amp;&gt;/dev/null
</span><span class='line'>
</span><span class='line'><span class="nb">read</span> -p <span class="s2">&quot;Remove Build directory? [Y/n]? &quot;</span> yn
</span><span class='line'><span class="k">if</span> <span class="o">[</span> <span class="s2">&quot;$yn&quot;</span> <span class="o">=</span> <span class="s2">&quot;y&quot;</span> <span class="o">]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">    </span><span class="nb">printf</span> <span class="s2">&quot;\n%s\n&quot;</span> <span class="s2">&quot;Removing build directory...&quot;</span>
</span><span class='line'>    rm -rf <span class="s2">&quot;$builddir&quot;</span>
</span><span class='line'><span class="k">else</span>
</span><span class='line'><span class="k">    </span><span class="nb">printf</span> <span class="s2">&quot;%s\n&quot;</span> <span class="s2">&quot;Build completed.&quot;</span>
</span><span class='line'><span class="k">fi</span>
</span></code></pre></div></figure>


<p>This provides me the minimum level of automation I require—essentially only
around downloading and installing a package. It doesn&#8217;t automatically handle
dependencies, nor manage updating the packages; that remains, rightly in my
view, <em>my</em> responsibility.</p>

<p>If I were to look to a more fully featured wrapper, I would undoubtedly choose
<a href="https://github.com/e36freak/meat" title="meat on Github">meat</a>, however as on my
desktop machine, I only have ~30 AUR packages installed, I don&#8217;t really need
anything more sophisticated.</p>

<p>So by all means, use an AUR helper. But recognize that it is intended to help
you, not preclude you from being able to accomplish the most simple and
critical task of system maintenance, updating your package manager. Uninstall
<code>yaourt</code> if you are using it and familiarize yourself with <code>makepkg</code>; once you
do understand the relationship between the official repositories and the AUR,
download <code>cower</code> or <code>meat</code>, they are both <em>much</em> better solutions.</p>

<h4>Notes</h4>

<ol>
<li><a href="http://jasonwryan.com/blog/2009/11/21/dzen2-and-conky-cli-in-dwm/" title="Post from 2009">Myself included</a>…</li>
</ol>


<p>Creative Commons image of crutches by
<a href="http://www.flickr.com/photos/wheatfields/118700600/" title="Flickr CC image">net_efekt on Flickr</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building Vim]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/03/29/vim/"/>
    <updated>2013-03-29T10:17:00+13:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/03/29/vim</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/vim-logo.png" title="'Vim logo'" >
Apart from a brief, but nevertheless instructive, flirtation with
<a href="http://www.gnu.org/software/emacs/" title="Emacs homepage">Emacs</a><sup>1</sup> I have
been a consistent <a href="http://www.vim.org/" title="Vim home">Vim</a> user over the last three
or four years. Like most Vim users, I have made some progress over that time
in spite of Vim&#8217;s
<a href="http://stackoverflow.com/a/1815372/712613" title="SO answer on Vim">notorious learning curve</a>
and have now reached the point where, belatedly, I think I understand it just enough
to really grasp how little I actually know. It&#8217;s a milestone that speaks more to
necessity than gratification, granted.</p>

<p>In any event, as part of confronting my Vim shortcomings (no
<a href="http://www.vimgolf.com/" title="Vim golf…">golfing</a> for me), I have been able
to land on the features of Vim that I require to be enabled so that I am moderately
productive (in my own, admittedly cloistered, working environment). That, you will
probably not be surprised to read, does not include needing support for Arabic or
Farsi to be built into Vim.</p>

<p>Part of the beauty of Vim is that, unlike it&#8217;s
<a href="http://en.wikipedia.org/wiki/Editor_war#Humor" title="…lacking a decent editor">operating system counterpart Emacs</a>,
you can choose how much functionality you wish to enable at compile-time. You do want
support for Farsi? Then the <code>--with-features=big</code> option is what you are looking for.
If, on the other hand, you just want the barest of bones, editor-wise, you could opt
for the austere minimalism that is <code>--with-features=tiny</code> and find yourself happily
transported back in time to
<a href="https://en.wikipedia.org/wiki/Vi" title="Wikipedia page on Vi">Bill Joy&#8217;s lab in 1976</a>.</p>

<p>You can peruse all of the various features available to Vim using the <code>:help version</code>
command.<sup>2</sup> There is also
<a href="http://www.drchip.org/astronaut/vim/vimfeat.html" title="Vim's versions and features">this table</a>
where the various features are listed against the respective feature flags (tiny, small,
normal, big &amp; huge).</p>

<p>After this
<a href="https://bugs.archlinux.org/task/33019" title="Add +profile to gvim on Flyspray">bug report</a>
late last year, the default Arch PKGBUILD ships with <code>huge</code> as the feature set. Make
what you will of that, but for my purposes it is overkill. With all the magic of
<a href="https://wiki.archlinux.org/index.php/Abs" title="Arch Wiki page on ABS">ABS</a> and
<code>makepkg</code>, however, it is simple enough to build a Vim package that is tailored
to exactly your requirements. For me, that means this set of simplified <code>configure</code>
options:</p>

<figure class='code'> <div class="highlight"><pre><code class='sh'><span class='line'>  ./configure <span class="se">\</span>
</span><span class='line'>    --prefix<span class="o">=</span>/usr <span class="se">\</span>
</span><span class='line'>    --localstatedir<span class="o">=</span>/var/lib/vim <span class="se">\</span>
</span><span class='line'>    --with-features<span class="o">=</span>normal <span class="se">\</span>
</span><span class='line'>    --with-compiledby<span class="o">=</span>Arch:jwr <span class="se">\</span>
</span><span class='line'>    --with-x<span class="o">=</span>yes <span class="se">\</span>
</span><span class='line'>    --enable-acl <span class="se">\</span>
</span><span class='line'>    --disable-gui <span class="se">\</span>
</span><span class='line'>    --disable-signs <span class="se">\</span>
</span><span class='line'>    --disable-netbeans <span class="se">\</span>
</span><span class='line'>    --enable-multibyte
</span></code></pre></div></figure>


<p>With these options, I have the minimum amount of functionality I comfortably
require (including the ability to access the system clipboard, <code>--with-x=yes</code>)
but without the other bloat.</p>

<p>In addition to these changes to the config options, I also strip out all of the
<code>gvim</code>-related stuff from the PKGBUILD as I do not require it. Even though it
is a split package, just building <code>vim</code> still includes options superfluous to
my needs.  As a result, I get Vim with just the features I need, without the
dependencies of <code>ruby</code> and <code>lua</code> and god knows what else.</p>

<p>I&#8217;m not operating under any illusions about the fact that this is
really saving a huge amount of space or, for that matter, drastically reducing the
number of dependencies I have installed. It is partly about understanding how Vim
works at another level while also catering for the obsessive-compulsive drive to
micro-control what is and isn&#8217;t installed on my systems. If you want to scratch either
of the same itches, you can see the full
<a href="https://bitbucket.org/jasonwryan/shiv/src/e6ccbe61780dfe24a5f7edda0d4b082dbb572e4a/Build/vim/PKGBUILD?at=default" title="Eviscerated Vim PKGBUILD">PKGBUILD in Bitbucket</a>.</p>

<h4>Notes</h4>

<ol>
<li>Still visible in some of my early Arch screenshots
<a href="http://www.flickr.com/photos/jasonwryan/3748882572/in/photostream" title="Emacs in Openbox">on Flickr</a>…</li>
<li>The official documentation for the features is also
<a href="http://vimdoc.sourceforge.net/htmldoc/various.html#+feature-list" title="Vim Feature list">online</a>.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[BitTorrent Sync Alpha]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/03/16/sync/"/>
    <updated>2013-03-16T10:17:00+13:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/03/16/sync</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/syncapp.png" title="'BitTorrent Sync logo'" >
I have posted about using <a href="http://dropbox.com" title="dropbox homepage">dropbox</a> quite
<a href="https://duckduckgo.com/?sites=jasonwryan.com&amp;q=dropbox" title="DDG search results">a few times</a>
over the last couple of years; it is one of those utilities that quickly insinuates itself
into an indispensable niche in your workflow and, consequently, can be <em>very</em> difficult to
dislodge. Perhaps because it has started to glue together so much of the way I work, I have
been wondering when I would find a replacement that would deliver all, or much, of the
functionality, without the standard
<a href="http://arstechnica.com/security/2012/07/dropbox-confirms-it-got-hacked-will-offer-two-factor-authentication/" title="Ars post on the dropbox hack">cloud security issues</a>,
that seem to bedevil these services.<sup>1</sup></p>

<p>When I saw that BitTorrent had release a distributed synching app called—appropriately—
<a href="http://blog.bittorrent.com/2013/01/24/test-bittorrent-sync-pre-alpha/" title="Blog post on sync release">Sync</a>,
I <a href="http://labs.bittorrent.com/experiments/sync.html" title="Invitation form">signed up for the Alpha</a> and
have been running it in lieu of dropbox for the past three weeks. My initial reaction is,
that for a first release, it is very impressive.</p>

<p>Essentially, Sync uses the
<a href="https://en.wikipedia.org/wiki/Bittorent" title="Wikipedia entry">bittorrent peer-to-peer protocol</a>
and encryption
(<a href="https://en.wikipedia.org/wiki/Aes_256" title="Wikipedia entry on the standard">AES 256</a>
using a private key based on the secret generated for each shared folder)
to sync files between your machines—or anyone with whom you share the secret
for a particular directory. This has several advantages over dropbox, from my perspective.
First and foremost, you are not relying on some third party for security<sup>2</sup>, storage
and uptime. Secondly, all of the traffic between your devices is encrypted. And finally,
it is free (sadly, only as in beer).</p>

<h3>Positives</h3>

<p>So what does it do well? It is ridiculously easy to setup. You download the binary, start
the app and then (on Linux) use the web interface to setup your first synching folder by
generating a secret and then nominating a folder to share. On your next machine, enter the
secret and select or create the shared folder and your files will be synched. Done.</p>

<p>On a headless machine, there is a config file that you can create:</p>

<figure class='code'> <div class="highlight"><pre><code class='sh'><span class='line'>syncapp --dump-sample-config &gt; syncapp.conf
</span></code></pre></div></figure>


<p>Edit it to suit your requirements, and then start <code>syncapp</code> with that configuration:</p>

<figure class='code'> <div class="highlight"><pre><code class='sh'><span class='line'>syncapp --config /path/to/syncapp.conf
</span></code></pre></div></figure>


<p>and you are away, happily synching.</p>

<p>Like other applications that use the bittorrent protocol, it can take a minute or
two for the synching to begin, but once it does I found it—over the Internet as well
as my <acronym title="Local Area Network">LAN</acronym> to be much faster than
dropbox. Another plus.</p>

<h3>Areas for improvement</h3>

<p>It is Alpha software so there are some areas where you can expect to see improvements
with subsequent release. For me, that includes:</p>

<ul>
<li>Better command line tools; the current limited set are servicable, but could do
with more flexibility and options</li>
<li>The ability to create your own secret, rather than rely on generated ones</li>
<li>A less fragile config file; it is written in JSON and the simplest errors will
break it</li>
<li>More Linux love; the other platforms have a much more sophisticated <acronym title="User Interface">UI</acronym></li>
</ul>


<p>A comparison with dropbox is not entirely fair; there are some things that dropbox
does—like versioning—that Sync can/will not do. Dropbox also allows you to host
public files and folders, meaning that you can
<a href="http://jasonwryan.com/blog/2010/01/11/using-dropbox-to-share-dotfiles/" title="Post on using dropbox to host dotfiles">setup a basic webpage</a>
or <a href="https://www.dropbox.com/sh/t6ko1rbl9edy8p4/OkwVLtY5fO" title="My Top 10 Albums">share a photo album</a>.
Sync clearly isn&#8217;t designed for this.</p>

<p>However, in some other respects, like architectures
for example, Sync is already a better choice. The ARMv6 port means that I am able
to run it on my Raspberry Pi, and that I have been able to update my
<a href="http://jasonwryan.com/blog/2011/11/07/irc-dzen/" title="Post on IRC highlights">IRC notification system</a>
to use Sync rather than dropbox and it is working perfectly well.</p>

<p>There is one area, though, where I wish the BitTorrent team would be a lot more
forthcoming. There has been an unanswered question on the Sync forums for
over three weeks now asking
<a href="http://forum.bittorrent.com/topic/8816-will-syncapp-be-open-source/" title="Syncapp Forums">will Syncapp be open sourced?</a>
Aside from the issue of whether or not the source will be made available (and I am guessing
that given their reticence to answer the question on their boards the prognosis
is not promising) people using the application now should know under what terms
they are using it.</p>

<p>In the absence of any definitive licensing, I can only assume that the application
is covered by BitTorrent&#8217;s
<a href="http://www.bittorrent.com/legal/eula" title="Licensing agreement on BitTorrent site">default EULA</a>.
That ambiguity means that I am happy to participate in the
trial and provide feedback, but I won&#8217;t be using the app for any remotely
sensitive data and I am unlikely to do so until that issue is clarified.</p>

<p>I&#8217;ll install <a href="http://sparkleshare.org/" title="Sparkleshare site">Sparkleshare</a>
and give that a shot instead…</p>

<h4>Notes</h4>

<ol>
<li>Naturally, there are more issues at play here than just their (in)security policies.</li>
<li>Assuming, of course, you trust what BitTorrent pack into the binary…</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Forking Arch]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/03/02/forking/"/>
    <updated>2013-03-02T10:04:00+13:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/03/02/forking</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/fork.jpg" title="'Fork on Flickr'" >
Over the last couple of months there have been a number of discussions on the Arch boards
about the
<a href="https://wiki.archlinux.org/index.php/Forum_Etiquette#Arch_Linux_Distribution_Support_ONLY" title="Forum Etiquette">forum policy</a>
of only providing support for Arch Linux, culminating in this
<a href="https://bbs.archlinux.org/viewtopic.php?id=157361" title="Arch Forum thread">long thread about Archbang users</a>
(login required) being denied support and having their threads summarily
closed. As it emerged in the discussion, there seem to be two separate issues
at play here; the question of Arch-derivatives using the Arch brand (logo,
colours and even the forum style sheets), and how the wider community of
GNU/Linux distributions are treated on our boards.</p>

<p>The first issue is relatively simple to address. Allowing derivative
distributions to use the Arch brand is, in my view, a mistake. It dilutes the
value of the Arch “brand” and—as can be seen when people show up having
installed a derivative and thinking they are running Arch—just confuses people.</p>

<p>For some of these derivatives, like Archbang, there is an argument to be made
that once they have completed the installation process, they are in fact
running Arch, albeit an off-the-shelf version. I find this argument to be
specious. All of the derivatives that I have come across, in addition to
“simplifying”<sup>1</sup> the installation process and including <code>X</code> and some
sort of desktop or window manager by default, also make a number of other
system changes that invalidate their claim to being Arch by another name.</p>

<p>See this <a href="http://www.reddit.com/r/archlinux/comments/yj2v5/a_new_guibased_version_of_arch_has_gone_live/c5wc6yo" title="Reddit thread on Manjaro Linux">scathing review of Manjaro</a>
or Allan&#8217;s <a href="http://allanmcrae.com/2012/12/battle-of-the-arch-spin-offs/" title="Allan McRae's blog">roundup of the Arch Spin-Offs</a>
for the details on the decisions these developers make that mean it is not
practicable to support them on the Arch boards, nor desirable to do so in
future. As a distro, Arch is essentially vanilla packages, pacman and rolling
release, and a base on which
<a href="https://wiki.archlinux.org/index.php/The_Arch_Way#User-centric" title="The Arch Way">you build your preferred system</a>.
Changing two of those three means that you are not running Arch…</p>

<p>That leads in to the second point, which is I&#8217;ll paraphrase as “well, we are
all Linux users, so everyone should be welcome to ask for support from Arch
users.” It is a fine sentiment, but one that is neither
<a href="http://www.catb.org/esr/faqs/smart-questions.html#forum" title="ESR's seminal document">historically accurate</a>,
nor in the long term interests of Arch. I have harped on in the past about
<a href="http://jasonwryan.com/blog/2012/03/17/vampires/" title="My post on the taxonomy of suckers…">help vampires</a>
and last year I came across the perfect illustration of the unchecked effects
of this phenomena:</p>

<blockquote><p>Right now I&#8217;d say the bug queues are flooded with bugs that you can&#8217;t really act on… It&#8217;s a strain on the project that there are so many users that don&#8217;t really get it.</p><footer><strong>Alison Randall</strong> <cite>Ubuntu Technical Architect. Linux Format July 2012</cite></footer></blockquote>


<p>Your bugtracker becomes essentially unusable. Your forums end up the same way.
No-one ends up getting much in the way of assistance at all, let alone anything
approaching informed help. That may be an inevitable consequence of the
collision between considerable but still finite resources and a philosophy of being
the <acronym title="Operating System">OS</acronym> of the masses; Arch has
nothing like that in terms of resources, and a very different
<a href="https://wiki.archlinux.org/index.php/The_Arch_Way" title="The Arch Way, again…">philosophy</a>.</p>

<p>That philosophy doesn&#8217;t include anything about shortcuts or commoditized images
for a mass user base. It doesn&#8217;t mention making the installation and
maintenance of your system completely idiot-proof so as to facilitate a
relentless march to the very top of whatever spurious distro popularity ranking
system you subscribe to. And it certainly doesn&#8217;t say anything about your
entitlement to immediate and courteous support from the Arch community in the
face of your own inability to reach a minimum level of understanding of what it
is that you have installed on your hard drive.</p>

<p>If you think that you can just skip the whole tiresome
<a href="http://jasonwryan.com/blog/2013/02/08/documentation/" title="Post on documentation">RTFM thing</a>
by downloading a derivative and installing that, how exactly do you expect to be able
to run a rolling release distro that has, on average, a couple of
<a href="https://www.archlinux.org/news/" title="Arch news">significant changes</a> every year?</p>

<p>Sooner or later you are going to have to come to terms with <em>the responsibility</em>
that is an integral part of this type of rolling release and, if you have
installed it yourself, you will be much better placed to be able to build on
that understanding and broaden and deepen your knowledge of your system.</p>

<p>That is ultimately far more satisfying for you, and much more beneficial for
the rest of the community as it means that you will be more able and likely to
contribute back in whatever way that you can; reporting bugs to a functioning
bug tracker, editing the <a href="https://wiki.archlinux.org" title="The finest, actually">fine Wiki</a>,
maintaining packages in <a href="https://aur.archlinux.org" title="Arch User Repository">the AUR</a>,
submitting patches, etc.  Doing all the things that will
sustain Arch and continue to make it an attractive distribution for competent
GNU/Linux users and those that are willing to invest the time to become so.</p>

<h4>Notes</h4>

<ol>
<li>If you have used the Arch install scripts, you would appreciate that it is
not really possible to provide a simpler installation process.</li>
</ol>


<p>Creative Commons licensed image on Flickr by <a href="http://www.flickr.com/photos/pietroizzo/3514191996/">pietroizzo</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Read The Fine Manual]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/02/08/documentation/"/>
    <updated>2013-02-08T19:57:00+13:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/02/08/documentation</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/documents.jpg" title="'Documents on Flickr'" >
One of the canards about Free and Open Source Software that is peddled by the unscrupulous
marketers of proprietary software is that their product is superior because, among other
things, the scruffy, sandal-wearing Communists that write and distribute their software
for free do not bother to adequately document that software; thereby placing in jeopardy
the business processes in the enterprise that rely on said software to continue to
profitably grease the wheels of the juggernaut of Capitalism.</p>

<p>At heart, it really is an attempt to paint FOSS as a hobbyist&#8217;s pursuit, unworthy of
consideration by Fortune 500 <acronym title="Chief Inhibiting Officers">CIOs</acronym>
as it is not in the same league as “professional,” proprietary product. This
<acronym title="Fear, Uncertainty & Doubt">FUD</acronym> is not restricted to
the usual suspects; it has also been raised by other, presumably more
<a href="http://www.osnews.com/story/5180" title="Editorial on OS News">objective commentators</a>:</p>

<blockquote><p>Open Source documentation is terrible. There is no kinder way to put it. Even the commercially distributed software in the Open Source world has substandard documentation. (And believe me, as a technical writer coming from the Windows world, when I tell you that the commercial industrial standards are pretty low). Only a bare handful of Open Source software packages have any documentation at all. And out of the few that do, much of it is either unfinished, inaccurate, or outdated. What counts as explanatory text among geeks would bewilder a nuclear physicist, even a sober one.</p><footer><strong>OSNews Editorial, 2003</strong> <cite><a href='http://www.osnews.com/story/5180'>www.osnews.com/story/5180/&hellip;</a></cite></footer></blockquote>


<p>A more recent survey, published in 2010, identifed the same issue for businesses,
in slightly less histrionic language:</p>

<blockquote><p>The No. 1 reason for not choosing open-source solutions was lack of support followed by poor documentation.</p><footer><strong>Zenoss 2010 Survey</strong> <cite><a href='http://gigaom.com/2010/08/11/enterprise-yeah-were-cool-with-open-source/'>gigaom.com/2010/08/11/&hellip;</a></cite></footer></blockquote>


<p>My experience of FOSS documentation, particularly over the last twelve months, has been just the
opposite.</p>

<p>From the middle of 2012 on, I made a couple of significant changes in my computing
environment; I moved from
<a href="https://wiki.archlinux.org/index.php/SysVinit" title="Archwiki page…">SysVinit</a>
to <a href="http://freedesktop.org/wiki/Software/systemd" title="Project web page">systemd</a>,
garden variety to
<a href="http://jasonwryan.com/blog/2013/01/25/uefi/" title="My post on UEFI booting">UEFI booting</a>
and changed my shell from
<a href="http://www.gnu.org/software/bash/" title="GNU Bash page">Bash</a> to
<a href="http://www.zsh.org/" title="Zsh homepage, one of the ugliest on the Web">Zsh</a>.
In each of these cases I found myself having to turn to the documentation the
community has provided in order to understand the implications of the change,
and to familiarise myself with the new tool or approach.</p>

<p>I posted at the time about <a href="http://jasonwryan.com/blog/2012/08/04/systemd/" title="The Leap to systemd">moving to systemd</a>,
and I don&#8217;t think—in retrospect—I credited Lennart Poettering enough for the series of posts
he wrote detailing the design decisions and implementation of that system;
those posts (at the time 12, now
<a href="http://0pointer.de/blog/projects" title="Lennart Poettering's blog">grown to 20</a>)
are an impressively thorough, and thoughtful, document of the new init system.</p>

<p>Similarly, when I started reading about <acronym title="Universal Extensible Firmware Interface">UEFI</acronym>
booting, I quickly found myself at <a href="http://www.rodsbooks.com/" title="The author of… Just go there!">Rod Smith&#8217;s site</a>.
Rod has compiled an exhaustive and authoritative resource on <a href="http://www.rodsbooks.com/gdisk/" title="gdisk page">GPT</a>,
EFI Stub loading and UEFI booting in general. Reading through his clear, approachable
documentation made transitioning to UEFI a much simpler process than, given the
inherent complexity in the ecosystem, I would have thought possible.</p>

<p>Then there is Zsh.</p>

<blockquote><p>Because zsh contains many features, the zsh manual has been split into a number of sections…</p><footer><strong>zsh manual</strong> <cite><a href='http://linux.die.net/man/1/zsh'>linux.die.net/man/1/zsh/&hellip;</a></cite></footer></blockquote>


<p>And goes it on to list those <em>seventeen</em> sections. If you are not a fan of <code>man</code> pages<sup>1</sup>,
there is the
<a href="http://zsh.sourceforge.net/Doc/Release/zsh_toc.html" title="What it says on the tin…">Zsh Documentation</a>,
the <a href="http://zsh.sourceforge.net/Guide/zshguide.html" title="User's Guide">User&#8217;s Guide</a> and
<a href="http://zshwiki.org/home/" title="Zsh Wiki">wiki</a>. This amounts to a literally staggering
amount of information—it is no wonder that preconfigured zsh systems like
<a href="http://grml.org/zsh/" title="grml homepage">grml</a> are so popular; they provide
relatively simple ingress to the byzantine ways of this powerful shell.</p>

<p>Finally, also last year, I was privileged to chair the judging for the
<a href="http://www.nzosa.org.nz/" title="NZOSA site">2012 New Zealand Open Source Awards</a>.
This exposed me to the amazing contribution
<a href="http://man7.orgi/mtk.index.html" title="Man pages Michael maintains">Michael Kerrisk</a>
has made to GNU/Linux over the last decade. He is the author, or co-author, of
<em>over 300</em> <code>man</code> pages; and these aren&#8217;t the glamorous, application pages read
by the masses, but the system pages that document the kernel and <code>glibc</code>
<acronym title="Application Program Interface">APIs</acronym>.</p>

<p>All of this suggests to me that the state of documentation for FOSS is
anything but parlous. At every turn over the last year, when I needed to
be able to refer to documentation for a project, there was a surfeit of it.
And I have only touched on what would normally constitute the primary
sources; there is also all of the other community-driven documentation
around projects, like the
<a href="https://wiki.archlinux.org/" title="The BEST GNU/LINUX wiki on the web">Arch Wiki</a>
or the <a href="http://unix.stackexchange.com/" title="Unix &amp; Linux SE">Stack Exchange sites</a>,
the support available on forums, IRC, blog posts, etc.</p>

<p>Compared to the sterile, mostly out-of-date (and expensive) documentation that
accompanies proprietary software, FOSS is an Alexandrine utopia…</p>

<h4>Notes</h4>

<ol>
<li>And, god knows, <em>I am</em>; <code>man</code> pages are a constant source of knowledge
and delight (and pretty much the only way I can contribute to projects that
I am indebted to).</li>
</ol>


<p>Creative Commons image of documents by
<a href="http://www.flickr.com/photos/mwichary/2322639175/">Marcin Wichary</a> on Flickr.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hi-UEFI Way]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/01/25/uefi/"/>
    <updated>2013-01-25T19:35:00+13:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/01/25/uefi</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/uefi.jpg" title="'Samsung Series 9 Laptop'" >
Just before Christmas my
<a href="https://bitbucket.org/jasonwryan/eeepc/src" title="Bitbucket repo for Archer">EeePC 901</a> started
to behave erratically. Rather than prolong the final throes, I decided to replace it and,
after looking around and having played with a colleague&#8217;s
<a href="http://www.cnet.com.au/samsung-series-9-13-inch-2012-339341806.htm" title="CNet Review">Samsung Series 9</a>,
I decided that I would swallow my pride, pay the Windows tax and opt for one of these sleek, fast
little notebooks. Given my experience with it over the last six to eight weeks, I am confident that
it was a decision that I am unlikely to regret.</p>

<p>The machine came with
<a href="https://en.wikipedia.org/wiki/Windows_8#Secure_boot" title="Wikipedia entry on Windows 8">Secure Boot</a>
enabled and running Windows 8.<sup>1</sup> After sedulously ignoring the mounting number
of posts on the Arch boards that had <acronym title="Unified Extensible Firmware Interface">UEFI</acronym>
in the title, initially convinced that it had something to do with Apple hardware and therefore
would be unlikely to impact on me at any point in the future, I now found myself in the position of
having to understand all of the disparate elements involved in UEFI booting.</p>

<p>This proved to be a non-trivial task. It is not that there is insufficient information
available; quite the opposite. The Arch Wiki has a typically thorough
<a href="https://wiki.archlinux.org/index.php/UEFI" title="Arch Wiki page">entry on UEFI</a>; the real
challenge is revealed when you scroll to the bottom of that page to the
<a href="https://wiki.archlinux.org/index.php/UEFI#See_also" title="See also section">reference links</a>
where you begin to reach an appreciation that this isn&#8217;t a drop-in replacement for
Grub in the way <a href="http://jasonwryan.com/blog/2012/07/09/syslinux/" title="My post on moving to Syslinux">Syslinux was</a>,
for example. This is a whole new booting ecosystem.</p>

<p>I wanted a LVM on LUKS setup and, after reading <em>a lot</em> more documentation on
<a href="https://wiki.archlinux.org/index.php/UEFI_Bootloaders" title="Arch Wiki entry">UEFI bootloaders</a>,
<a href="https://wiki.archlinux.org/index.php/GPT" title="Arch Wiki GPT page">GUID Partition Tables</a> and
<a href="http://www.rodsbooks.com/efi-bootloaders/efistub.html" title="Rod Smith's excellent site">EFISTUB</a><sup>2</sup>
than I had bargained on, I felt reasonably well equipped to proceed. And while this was an
admittedly time consuming (and sometimes confusing) process, I believe it was worth it.</p>

<p>Once I had a reasonable grasp of the conceptual model—and I am convinced this is the single
biggest hurdle in this process—I chose the EFISTUB boot approach with
<a href="http://freedesktop.org/wiki/Software/gummiboot" title="gummiboot homepage">gummiboot</a>,
as the boot manager; mostly because it seemed the simplest approach (the name may also
have been a factor).</p>

<p>Armed with all this new knowledge, I embarked on the install process. It didn&#8217;t take long at
all. Mostly because I couldn&#8217;t boot in UEFI mode from the USB drive.</p>

<p>Turns out a couple of things were thwarting me; one I had disabled Secure Boot
in the UEFI menu, but had neglected to disable the fast boot option. Secondly,
and more worryingly, I kept encountering kernel panics once I had got the
machine to boot. Seems that booting in UEFI mode triggers a nasty
<a href="https://bugzilla.kernel.org/show_bug.cgi?id=47121" title="On the Kernel bugtracker">bug with the samsung_laptop module</a>.</p>

<p>Once I could boot from the USB drive, I was able to successfully complete the install.
Rather than include a blow-by-blow account of that process here, I
have uploaded
<a href="https://gist.github.com/4618490" title="Gist with installation details">a gist with the details</a>,
for the morbidly curious or preternaturally bored.</p>

<p>The whole process, for me, epitomised what Arch is really about. No matter how comfortable
a point you reach with your understanding of the tools you use, the rolling release model
constantly challenges you to adopt and adapt to new technologies. Sure, I could have just
opted to boot in regular BIOS mode, but what would be the point of that? I wouldn&#8217;t have
<em>learned</em> anything.</p>

<p>The other thing that quickly became apparent is that, contrary to some commentary
on the boards about the
<a href="https://www.archlinux.org/news/install-media-20120715-released/" title="News item on new install method">removal of the AIF</a>,
the new install scripts are quite superb; simple, direct and quite unambiguous, the whole
install procedure now feels a lot more Arch-like. The developers have done a great
job with these tools.</p>

<h4>Notes</h4>

<ol>
<li><p>Surely the worst operating system, at least in terms of the user interface, I have
had the misfortune to encounter (and I include Vista and Ubuntu&#8217;s Unity in that
cavalcade of fail)…</p></li>
<li><p>I&#8217;ll post more on the voluminous documentation around this, and other aspects of
GNU/Linux, in the coming weeks.</p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Replacing TrueCrypt]]></title>
    <link href="http://jasonwryan.github.com/blog/2013/01/10/truecrypt/"/>
    <updated>2013-01-10T16:02:00+13:00</updated>
    <id>http://jasonwryan.github.com/blog/2013/01/10/truecrypt</id>
    <content type="html"><![CDATA[<p><img class="left" src="http://miromiro.com/Blog-images/lock.jpg" title="'Flickr image of lock'" >
I have used <a href="http://truecrypt.org/" title="TrueCrypt homepage">TrueCrypt</a> since just before
I migrated to Linux, so somwehere around six or seven years, dating back to version 3 or 4.
It is an incredibly handy utility, allowing you to create and manage encrypted volumes on
the fly and—for the especially paranoid—to hide the existence of those volumes from
inquisitive others.</p>

<p>In the intervening years, with all aspects of my personal life
increasingly mediated digitally, in order to properly safeguard my privacy,
and that of my family, I have taken to using LUKS to
<a href="http://jasonwryan.com/blog/2012/02/11/lvm/" title="Post on LVM on LUKS">fully encrypt all of my machines</a>.
And I have used TrueCrypt, both personally and for work, to encrypt some of my USB drives and as
a container in <a href="http://dropbox.com/" title="Dropbox homepage">Dropbox</a>
, for as long as
<a href="http://jasonwryan.com/blog/2010/01/11/using-dropbox-to-share-dotfiles/" title="Post on sharing dotfiles with Dropbox">I have used that service</a>.</p>

<p>Early last year, however, I became aware of concerns that TrueCrypt was not truly open source; that almost
all of the larger distros, including Arch, and the Open Source Initiative did not regard TrueCrypt as
free (as in Freedom) software:</p>

<blockquote><p>The TrueCrypt License has not been officially approved by the Open Source Initiative and is not considered &#8220;free&#8221; by several major Linux distributions (Arch Linux, Debian, Ubuntu, Fedora, openSUSE, Gentoo), mainly because of distribution and copyright-liability reasons.</p><footer><strong>Wikipedia entry on TrueCrypt</strong> <cite><a href='https://en.wikipedia.org/wiki/Truecrypt'>en.wikipedia.org/wiki/Truecrypt/&hellip;</a></cite></footer></blockquote>


<p>When I initially accessed the page, in February 2012, there was also a paragraph—now removed—that
highlighted further, more alarmist, concerns about the shadowy identity of the people behind
TrueCrypt:</p>

<blockquote><p>The anonymity of the developers and the abnormalities mentioned above have led users to raise suspicions about the provenance of the product and speculate about the possible existence of vulnerabilities or backdoors that might exist in the source code or executables. http://www.privacylover.com/encryption/analysis-is-there-a-backdoor-in-truecrypt-is-truecrypt-a-cia-honeypot/ However its open source and it can be check for funerabilities that way. [sic]</p><footer><strong>Wikipedia entry retrieved in February 2012</strong> <cite><a href='https://en.wikipedia.org/w/index.php?title=TrueCrypt&diff=478623780&oldid=478608477'>en.wikipedia.org/w/&hellip;</a></cite></footer></blockquote>


<p>While I don&#8217;t subscribe to the theory that the CIA have planted a backdoor in the software (if they
had, <a href="https://en.wikipedia.org/wiki/Truecrypt#Operation_Satyagraha" title="FBI operation foiled by TC">it clearly doesn&#8217;t work</a>),
I was relieved to see at the end of last year that someone had written a simple utility that allows
you to manage TrueCrypt containers from the command line; <a href="https://github.com/bwalex/tc-play" title="tcplay on Guthub">tcplay</a>
is decribed as:</p>

<blockquote><p>a free (BSD-licensed), pretty much fully featured (including multiple keyfiles, cipher cascades, etc) and stable TrueCrypt implementation.</p></blockquote>


<p>With a <a href="https://github.com/bwalex/tc-play/blob/master/LICENSE" title="tcplay license">simple, two paragraph license</a>
and a brief but comprehensive <code>man</code> page, I was sold. I uninstalled TrueCrypt late last year and haven&#8217;t missed it since. Quite
the contrary. The only “issue” that I have had with tcplay is remembering the commands to map and mount a drive.
Initially, I jotted down some notes, but opening them up several times a week to refer to them quickly seemed
pointless so I eventually wised up and wrote a wrapper script to do the job for me…</p>

<p>The script is quite simple, it finds the first available loop device, maps the encrypted volume to it and
mounts it read-writeable for your user.</p>

<figure class='code'> <div class="highlight"><pre><code class='sh'><span class='line'><span class="c">#!/bin/bash</span>
</span><span class='line'><span class="c"># manage truecrypt containers using tcplay</span>
</span><span class='line'>
</span><span class='line'><span class="nv">user</span><span class="o">=</span>jason
</span><span class='line'><span class="nv">cryptdev</span><span class="o">=</span>Safebox
</span><span class='line'><span class="nv">cryptpath</span><span class="o">=</span>/home/jason/Dropbox/<span class="s2">&quot;$cryptdev&quot;</span>
</span><span class='line'><span class="nv">loopdev</span><span class="o">=</span><span class="k">$(</span>losetup -f<span class="k">)</span>
</span><span class='line'><span class="nv">mountpt</span><span class="o">=</span>/media/<span class="s2">&quot;$cryptdev&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="c"># must be run as root</span>
</span><span class='line'><span class="k">if</span> <span class="o">[[</span> <span class="nv">$EUID</span> !<span class="o">=</span> 0 <span class="o">]]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">  </span><span class="nb">printf</span> <span class="s2">&quot;%s\n&quot;</span> <span class="s2">&quot;You must be root to run this.&quot;</span>
</span><span class='line'>  <span class="nb">exit </span>1
</span><span class='line'><span class="k">fi</span>
</span><span class='line'>
</span><span class='line'><span class="c"># unecrypt and mount container</span>
</span><span class='line'><span class="k">if</span> <span class="o">[[</span> <span class="s2">&quot;$1&quot;</span> <span class="o">==</span> <span class="s2">&quot;open&quot;</span> <span class="o">]]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">  </span>losetup <span class="s2">&quot;$loopdev&quot;</span> <span class="s2">&quot;$cryptpath&quot;</span>
</span><span class='line'>  tcplay --map<span class="o">=</span><span class="s2">&quot;$cryptdev&quot;</span> --device<span class="o">=</span><span class="s2">&quot;$loopdev&quot;</span>
</span><span class='line'>
</span><span class='line'>  <span class="c"># read passphrase</span>
</span><span class='line'>  <span class="nb">read</span> -r -s passphrase <span class="s">&lt;&lt;EOF</span>
</span><span class='line'><span class="s">  &quot;$passphrase&quot;</span>
</span><span class='line'><span class="s">EOF</span>
</span><span class='line'>
</span><span class='line'>  <span class="c"># mount container</span>
</span><span class='line'>  <span class="o">[[</span> -d <span class="s2">&quot;$mountpt&quot;</span> <span class="o">]]</span> <span class="o">||</span> mkdir <span class="s2">&quot;$mountpt&quot;</span>
</span><span class='line'>
</span><span class='line'>  <span class="c"># mount options</span>
</span><span class='line'>  <span class="nv">userid</span><span class="o">=</span><span class="k">$(</span>awk -F<span class="s2">&quot;[=(]&quot;</span> <span class="s1">&#39;{print $2,$4}&#39;</span> &lt;<span class="o">(</span>id <span class="s2">&quot;$user&quot;</span><span class="k">)</span><span class="o">)</span>
</span><span class='line'>  mount -o nosuid,uid<span class="o">=</span><span class="s2">&quot;${userid% *}&quot;</span>,gid<span class="o">=</span><span class="s2">&quot;${userid#* }&quot;</span> /dev/mapper/<span class="s2">&quot;$cryptdev&quot;</span> <span class="s2">&quot;$mountpt&quot;</span>
</span><span class='line'>
</span><span class='line'><span class="c"># close and clean up…</span>
</span><span class='line'><span class="k">elif</span> <span class="o">[[</span> <span class="s2">&quot;$1&quot;</span> <span class="o">==</span> <span class="s2">&quot;close&quot;</span> <span class="o">]]</span>; <span class="k">then</span>
</span><span class='line'><span class="k">  </span><span class="nv">device</span><span class="o">=</span><span class="k">$(</span>awk -v <span class="nv">dev</span><span class="o">=</span><span class="nv">$cryptdev</span> -F<span class="s2">&quot;:&quot;</span> <span class="s1">&#39;/dev/ {print $1}&#39;</span> &lt;<span class="o">(</span>losetup -a<span class="k">)</span><span class="o">)</span>
</span><span class='line'>  umount <span class="s2">&quot;$mountpt&quot;</span>
</span><span class='line'>  dmsetup remove <span class="s2">&quot;$cryptdev&quot;</span> <span class="o">||</span> <span class="nb">printf</span> <span class="s2">&quot;%s\n&quot;</span> <span class="s2">&quot;demapping failed&quot;</span>
</span><span class='line'>  losetup -d <span class="s2">&quot;$device&quot;</span> <span class="o">||</span> <span class="nb">printf</span> <span class="s2">&quot;%s\n&quot;</span> <span class="s2">&quot;deleting $loopdev failed&quot;</span>
</span><span class='line'><span class="k">else</span>
</span><span class='line'><span class="k">  </span><span class="nb">printf</span> <span class="s2">&quot;%s\n&quot;</span> <span class="s2">&quot;Options are open or close.&quot;</span>
</span><span class='line'><span class="k">fi</span>
</span></code></pre></div></figure>


<p>Once you are done, the script will unmount your volume and clean up. Undoubtedly, the
script could be improved; patches are welcome.</p>

<p>There is a
<a href="https://aur.archlinux.org/packages/tcplay-git/" title="Arch User Repository">PKGBUILD in the AUR</a>.
Uninstall TrueCrypt and give tcplay a go, it is a simple, powerful application; and it <em>is</em>
free software…</p>

<h4>Notes</h4>

<p>Creative Commons image on Flickr by <a href="http://www.flickr.com/photos/xserve/368758286/" title="Licensed CC by xserv">xserv</a>.</p>
]]></content>
  </entry>
  
</feed>
